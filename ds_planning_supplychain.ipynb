{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demand Forecasting: Developing models to predict future demand for various products accurately. This involves analyzing historical sales data, market trends, seasonality, and external factors like economic indicators or events that could influence demand. Accurate forecasts are crucial for planning production, inventory levels, and avoiding stockouts or excess inventory.\n",
    "\n",
    "Supply Chain Optimization: Identifying the most efficient and cost-effective strategies for sourcing materials, manufacturing, and distributing products to retailers or directly to consumers. This might involve route optimization, supplier selection, and evaluating make-or-buy decisions.\n",
    "\n",
    "Inventory Management: Developing algorithms to optimize inventory levels across different warehouses and retail outlets to ensure that products are available where and when they're needed, minimizing holding costs and reducing the risk of stockouts or overstock situations.\n",
    "\n",
    "Product Lifecycle Management: Analyzing sales and customer feedback data to determine the lifecycle stage of each product, helping the company decide when to introduce new models, discontinue products, or run promotions to clear out inventory.\n",
    "\n",
    "Cost Reduction and Efficiency Improvement: Identifying opportunities to reduce costs and improve operational efficiency across the supply chain. This could involve automating manual processes, improving the accuracy of demand planning to reduce the need for expedited shipping, and optimizing the product mix to maximize profitability.\n",
    "\n",
    "Risk Management: Assessing and mitigating risks related to supply chain disruption, such as supplier reliability, geopolitical factors, natural disasters, and pandemics. Developing contingency plans and strategies to ensure supply chain resilience.\n",
    "\n",
    "Sustainability Analysis: Evaluating the environmental impact of supply chain operations and identifying opportunities to reduce carbon footprint, waste, and improve sustainability practices in production and distribution.\n",
    "\n",
    "Customer Experience Enhancement: Analyzing customer feedback and return data to identify issues with product quality or features that could be improved. Working with product development and quality assurance teams to address these issues can enhance customer satisfaction and loyalty.\n",
    "\n",
    "Market Trend Analysis: Keeping abreast of market trends and technological advancements in the home appliance sector to forecast shifts in consumer preferences and emerging opportunities or threats.\n",
    "\n",
    "Supplier Performance Management: Developing metrics and monitoring systems to assess supplier performance in terms of quality, delivery, and cost. This information can be used to negotiate better terms, identify areas for improvement, or make decisions about changing suppliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1- Demand Forecasting: Developing models to predict future demand for various products accurately. This involves analyzing historical sales data, market trends, seasonality, and external factors like economic indicators or events that could influence demand. Accurate forecasts are crucial for planning production, inventory levels, and avoiding stockouts or excess inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>QuantitySold</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>PoliticalEvents</th>\n",
       "      <th>StockLevels</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>SupplierPerformance</th>\n",
       "      <th>CustomerSegment</th>\n",
       "      <th>PurchaseHistory</th>\n",
       "      <th>ProductRatingsReviews</th>\n",
       "      <th>Features</th>\n",
       "      <th>LaunchDate</th>\n",
       "      <th>LifeCycleStage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AXX-284</td>\n",
       "      <td>Population</td>\n",
       "      <td>Dryer</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>1767.49</td>\n",
       "      <td>8297.32</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Senior</td>\n",
       "      <td>{\"key\": \"cause\", \"value\": 23638724}</td>\n",
       "      <td>2.27</td>\n",
       "      <td>{\"key\": \"my\", \"value\": 567049}</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>Decline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHb-183</td>\n",
       "      <td>Care</td>\n",
       "      <td>Washer</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>695.98</td>\n",
       "      <td>4474.01</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Youth</td>\n",
       "      <td>{\"key\": \"weight\", \"value\": 7}</td>\n",
       "      <td>4.67</td>\n",
       "      <td>{\"key\": \"see\", \"value\": 88703295}</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>Introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QBK-760</td>\n",
       "      <td>Job</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>1200.98</td>\n",
       "      <td>2609.65</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "      <td>0.87</td>\n",
       "      <td>Senior</td>\n",
       "      <td>{\"key\": \"between\", \"value\": 35}</td>\n",
       "      <td>3.70</td>\n",
       "      <td>{\"key\": \"sure\", \"value\": 738250840}</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>Introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqe-765</td>\n",
       "      <td>Back</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>1893.33</td>\n",
       "      <td>9228.89</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>26</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Adult</td>\n",
       "      <td>{\"key\": \"team\", \"value\": 8740}</td>\n",
       "      <td>1.17</td>\n",
       "      <td>{\"key\": \"herself\", \"value\": 88470213}</td>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>Growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUN-031</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Washer</td>\n",
       "      <td>41</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>1434.96</td>\n",
       "      <td>6755.29</td>\n",
       "      <td>Online</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>73</td>\n",
       "      <td>21</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Senior</td>\n",
       "      <td>{\"key\": \"ever\", \"value\": 72771}</td>\n",
       "      <td>3.41</td>\n",
       "      <td>{\"key\": \"turn\", \"value\": 89}</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>Maturity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductID ProductName      Category  QuantitySold   SalesDate  UnitPrice  \\\n",
       "0   AXX-284  Population         Dryer             2  2023-04-08    1767.49   \n",
       "1   FHb-183        Care        Washer             6  2022-08-23     695.98   \n",
       "2   QBK-760         Job     Microwave            10  2022-12-17    1200.98   \n",
       "3   Aqe-765        Back  Refrigerator            29  2023-04-15    1893.33   \n",
       "4   NUN-031     Natural        Washer            41  2023-06-05    1434.96   \n",
       "\n",
       "   Revenue      Channel    Weekday  Month  ...  PoliticalEvents  StockLevels  \\\n",
       "0  8297.32  Distributor    Tuesday      5  ...             True           13   \n",
       "1  4474.01  Distributor     Monday      3  ...             True           19   \n",
       "2  2609.65     In-store   Saturday      9  ...            False           75   \n",
       "3  9228.89     In-store    Tuesday      7  ...            False           92   \n",
       "4  6755.29       Online  Wednesday      5  ...            False           73   \n",
       "\n",
       "   LeadTime SupplierPerformance CustomerSegment  \\\n",
       "0        28                0.76          Senior   \n",
       "1        29                0.60           Youth   \n",
       "2        16                0.87          Senior   \n",
       "3        26                0.72           Adult   \n",
       "4        21                0.96          Senior   \n",
       "\n",
       "                       PurchaseHistory  ProductRatingsReviews  \\\n",
       "0  {\"key\": \"cause\", \"value\": 23638724}                   2.27   \n",
       "1        {\"key\": \"weight\", \"value\": 7}                   4.67   \n",
       "2      {\"key\": \"between\", \"value\": 35}                   3.70   \n",
       "3       {\"key\": \"team\", \"value\": 8740}                   1.17   \n",
       "4      {\"key\": \"ever\", \"value\": 72771}                   3.41   \n",
       "\n",
       "                                Features  LaunchDate  LifeCycleStage  \n",
       "0         {\"key\": \"my\", \"value\": 567049}  2023-08-19         Decline  \n",
       "1      {\"key\": \"see\", \"value\": 88703295}  2021-12-06    Introduction  \n",
       "2    {\"key\": \"sure\", \"value\": 738250840}  2023-11-09    Introduction  \n",
       "3  {\"key\": \"herself\", \"value\": 88470213}  2021-09-27          Growth  \n",
       "4           {\"key\": \"turn\", \"value\": 89}  2019-11-18        Maturity  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import json\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Function to generate random JSON for complex data columns\n",
    "def generate_random_json():\n",
    "    return json.dumps({'key': fake.word(), 'value': fake.random_number()})\n",
    "\n",
    "# Sample data generation\n",
    "data = {\n",
    "    'ProductID': [fake.bothify(text='???-###') for _ in range(100)],\n",
    "    'ProductName': [fake.word().capitalize() for _ in range(100)],\n",
    "    'Category': [random.choice(['Refrigerator', 'Microwave', 'Washer', 'Dryer', 'Oven']) for _ in range(100)],\n",
    "    'QuantitySold': np.random.randint(1, 50, size=100),\n",
    "    'SalesDate': [fake.date_between(start_date='-2y', end_date='today') for _ in range(100)],\n",
    "    'UnitPrice': np.random.uniform(100, 2000, size=100).round(2),\n",
    "    'Revenue': np.random.uniform(200, 10000, size=100).round(2),\n",
    "    'Channel': [random.choice(['Online', 'In-store', 'Distributor']) for _ in range(100)],\n",
    "    'Weekday': [fake.day_of_week() for _ in range(100)],\n",
    "    'Month': np.random.randint(1, 13, size=100),\n",
    "    'Quarter': np.random.randint(1, 5, size=100),\n",
    "    'Year': np.random.randint(2019, 2023, size=100),\n",
    "    'Holiday': np.random.choice([True, False], size=100),\n",
    "    'EconomicIndicators': [generate_random_json() for _ in range(100)],\n",
    "    'MarketTrends': [generate_random_json() for _ in range(100)],\n",
    "    'CompetitorPricing': np.random.uniform(100, 2000, size=100).round(2),\n",
    "    'Promotions': np.random.choice([True, False], size=100),\n",
    "    'WeatherConditions': [random.choice(['Sunny', 'Rainy', 'Snowy', 'Cloudy']) for _ in range(100)],\n",
    "    'PoliticalEvents': np.random.choice([True, False], size=100),\n",
    "    'StockLevels': np.random.randint(0, 100, size=100),\n",
    "    'LeadTime': np.random.randint(1, 30, size=100),\n",
    "    'SupplierPerformance': np.random.uniform(0.5, 1.0, size=100).round(2),\n",
    "    'CustomerSegment': [random.choice(['Youth', 'Adult', 'Senior']) for _ in range(100)],\n",
    "    'PurchaseHistory': [generate_random_json() for _ in range(100)],\n",
    "    'ProductRatingsReviews': np.random.uniform(1, 5, size=100).round(2),\n",
    "    'Features': [generate_random_json() for _ in range(100)],\n",
    "    'LaunchDate': [fake.date_between(start_date='-5y', end_date='today') for _ in range(100)],\n",
    "    'LifeCycleStage': [random.choice(['Introduction', 'Growth', 'Maturity', 'Decline']) for _ in range(100)],\n",
    "}\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15100/2677859634.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.iloc[nan_indices, df.columns.get_loc(col)] = np.nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>QuantitySold</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>PoliticalEvents</th>\n",
       "      <th>StockLevels</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>SupplierPerformance</th>\n",
       "      <th>CustomerSegment</th>\n",
       "      <th>PurchaseHistory</th>\n",
       "      <th>ProductRatingsReviews</th>\n",
       "      <th>Features</th>\n",
       "      <th>LaunchDate</th>\n",
       "      <th>LifeCycleStage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Population</td>\n",
       "      <td>Dryer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1767.49</td>\n",
       "      <td>8297.32</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Senior</td>\n",
       "      <td>{\"key\": \"cause\", \"value\": 23638724}</td>\n",
       "      <td>2.27</td>\n",
       "      <td>{\"key\": \"my\", \"value\": 567049}</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>Decline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHb-183</td>\n",
       "      <td>Care</td>\n",
       "      <td>Washer</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>695.98</td>\n",
       "      <td>4474.01</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Youth</td>\n",
       "      <td>{\"key\": \"weight\", \"value\": 7}</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>Introduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Job</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>1200.98</td>\n",
       "      <td>2609.65</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>75.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"key\": \"between\", \"value\": 35}</td>\n",
       "      <td>3.70</td>\n",
       "      <td>{\"key\": \"sure\", \"value\": 738250840}</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqe-765</td>\n",
       "      <td>Back</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>1893.33</td>\n",
       "      <td>9228.89</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>92.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Adult</td>\n",
       "      <td>{\"key\": \"team\", \"value\": 8740}</td>\n",
       "      <td>1.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>Growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUN-031</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Washer</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>1434.96</td>\n",
       "      <td>6755.29</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Senior</td>\n",
       "      <td>{\"key\": \"ever\", \"value\": 72771}</td>\n",
       "      <td>3.41</td>\n",
       "      <td>{\"key\": \"turn\", \"value\": 89}</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>Maturity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductID ProductName      Category  QuantitySold   SalesDate  UnitPrice  \\\n",
       "0       NaN  Population         Dryer           2.0         NaN    1767.49   \n",
       "1   FHb-183        Care        Washer           6.0  2022-08-23     695.98   \n",
       "2       NaN         Job     Microwave          10.0  2022-12-17    1200.98   \n",
       "3   Aqe-765        Back  Refrigerator          29.0  2023-04-15    1893.33   \n",
       "4   NUN-031     Natural        Washer          41.0  2023-06-05    1434.96   \n",
       "\n",
       "   Revenue      Channel   Weekday  Month  ...  PoliticalEvents  StockLevels  \\\n",
       "0  8297.32  Distributor   Tuesday    5.0  ...              NaN         13.0   \n",
       "1  4474.01  Distributor    Monday    3.0  ...              NaN         19.0   \n",
       "2  2609.65     In-store  Saturday    9.0  ...            False         75.0   \n",
       "3  9228.89     In-store   Tuesday    7.0  ...            False         92.0   \n",
       "4  6755.29       Online       NaN    5.0  ...              NaN         73.0   \n",
       "\n",
       "  LeadTime SupplierPerformance CustomerSegment  \\\n",
       "0     28.0                0.76          Senior   \n",
       "1     29.0                 NaN           Youth   \n",
       "2     16.0                0.87             NaN   \n",
       "3     26.0                0.72           Adult   \n",
       "4     21.0                0.96          Senior   \n",
       "\n",
       "                       PurchaseHistory ProductRatingsReviews  \\\n",
       "0  {\"key\": \"cause\", \"value\": 23638724}                  2.27   \n",
       "1        {\"key\": \"weight\", \"value\": 7}                  4.67   \n",
       "2      {\"key\": \"between\", \"value\": 35}                  3.70   \n",
       "3       {\"key\": \"team\", \"value\": 8740}                  1.17   \n",
       "4      {\"key\": \"ever\", \"value\": 72771}                  3.41   \n",
       "\n",
       "                              Features  LaunchDate  LifeCycleStage  \n",
       "0       {\"key\": \"my\", \"value\": 567049}  2023-08-19         Decline  \n",
       "1                                  NaN  2021-12-06    Introduction  \n",
       "2  {\"key\": \"sure\", \"value\": 738250840}  2023-11-09             NaN  \n",
       "3                                  NaN  2021-09-27          Growth  \n",
       "4         {\"key\": \"turn\", \"value\": 89}  2019-11-18        Maturity  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to randomly insert NaN values into each column\n",
    "def insert_random_nans(df, fraction=0.1):\n",
    "    assert 0 < fraction < 1, \"Fraction must be between 0 and 1\"\n",
    "\n",
    "    nrows, ncols = df.shape\n",
    "    for col in df.columns:\n",
    "        # Number of NaNs to insert\n",
    "        n_nans = int(np.floor(nrows * fraction))\n",
    "        # Randomly choose indices to replace with NaNs\n",
    "        nan_indices = np.random.choice(nrows, n_nans, replace=False)\n",
    "        df.iloc[nan_indices, df.columns.get_loc(col)] = np.nan\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "insert_random_nans(df, fraction=0.1)  # This will replace ~10% of values in each column with NaNs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect dataset df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract json values into new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>QuantitySold</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>LaunchDate</th>\n",
       "      <th>LifeCycleStage</th>\n",
       "      <th>EconomicIndicators_Key</th>\n",
       "      <th>EconomicIndicators_Value</th>\n",
       "      <th>MarketTrends_Key</th>\n",
       "      <th>MarketTrends_Value</th>\n",
       "      <th>PurchaseHistory_Key</th>\n",
       "      <th>PurchaseHistory_Value</th>\n",
       "      <th>Features_Key</th>\n",
       "      <th>Features_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Population</td>\n",
       "      <td>Dryer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1767.49</td>\n",
       "      <td>8297.32</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>Decline</td>\n",
       "      <td>election</td>\n",
       "      <td>4404.0</td>\n",
       "      <td>toward</td>\n",
       "      <td>431973732.0</td>\n",
       "      <td>cause</td>\n",
       "      <td>23638724.0</td>\n",
       "      <td>my</td>\n",
       "      <td>567049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHb-183</td>\n",
       "      <td>Care</td>\n",
       "      <td>Washer</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>695.98</td>\n",
       "      <td>4474.01</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>where</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>weight</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Job</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>1200.98</td>\n",
       "      <td>2609.65</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lead</td>\n",
       "      <td>5077492.0</td>\n",
       "      <td>onto</td>\n",
       "      <td>95.0</td>\n",
       "      <td>between</td>\n",
       "      <td>35.0</td>\n",
       "      <td>sure</td>\n",
       "      <td>738250840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqe-765</td>\n",
       "      <td>Back</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>1893.33</td>\n",
       "      <td>9228.89</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>Growth</td>\n",
       "      <td>start</td>\n",
       "      <td>7499883.0</td>\n",
       "      <td>nation</td>\n",
       "      <td>434.0</td>\n",
       "      <td>team</td>\n",
       "      <td>8740.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUN-031</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Washer</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>1434.96</td>\n",
       "      <td>6755.29</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>Maturity</td>\n",
       "      <td>direction</td>\n",
       "      <td>36168.0</td>\n",
       "      <td>five</td>\n",
       "      <td>9845051.0</td>\n",
       "      <td>ever</td>\n",
       "      <td>72771.0</td>\n",
       "      <td>turn</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductID ProductName      Category  QuantitySold   SalesDate  UnitPrice  \\\n",
       "0       NaN  Population         Dryer           2.0         NaN    1767.49   \n",
       "1   FHb-183        Care        Washer           6.0  2022-08-23     695.98   \n",
       "2       NaN         Job     Microwave          10.0  2022-12-17    1200.98   \n",
       "3   Aqe-765        Back  Refrigerator          29.0  2023-04-15    1893.33   \n",
       "4   NUN-031     Natural        Washer          41.0  2023-06-05    1434.96   \n",
       "\n",
       "   Revenue      Channel   Weekday  Month  ...  LaunchDate  LifeCycleStage  \\\n",
       "0  8297.32  Distributor   Tuesday    5.0  ...  2023-08-19         Decline   \n",
       "1  4474.01  Distributor    Monday    3.0  ...  2021-12-06    Introduction   \n",
       "2  2609.65     In-store  Saturday    9.0  ...  2023-11-09             NaN   \n",
       "3  9228.89     In-store   Tuesday    7.0  ...  2021-09-27          Growth   \n",
       "4  6755.29       Online       NaN    5.0  ...  2019-11-18        Maturity   \n",
       "\n",
       "  EconomicIndicators_Key  EconomicIndicators_Value MarketTrends_Key  \\\n",
       "0               election                    4404.0           toward   \n",
       "1                  where                       9.0             None   \n",
       "2                   lead                 5077492.0             onto   \n",
       "3                  start                 7499883.0           nation   \n",
       "4              direction                   36168.0             five   \n",
       "\n",
       "  MarketTrends_Value PurchaseHistory_Key  PurchaseHistory_Value  Features_Key  \\\n",
       "0        431973732.0               cause             23638724.0            my   \n",
       "1                NaN              weight                    7.0          None   \n",
       "2               95.0             between                   35.0          sure   \n",
       "3              434.0                team                 8740.0          None   \n",
       "4          9845051.0                ever                72771.0          turn   \n",
       "\n",
       "   Features_Value  \n",
       "0        567049.0  \n",
       "1             NaN  \n",
       "2     738250840.0  \n",
       "3             NaN  \n",
       "4            89.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to check if a cell contains a valid JSON object with 'key' and 'value'\n",
    "def is_valid_json(cell):\n",
    "    try:\n",
    "        json_obj = json.loads(cell)\n",
    "        return 'key' in json_obj and 'value' in json_obj\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Loop through each column in the DataFrame\n",
    "for col in df.columns:\n",
    "    # Check the first row to see if it contains the JSON pattern we're interested in\n",
    "    # Assuming if one row is JSON, the rest are too. Adjust logic as needed for your use case.\n",
    "    if is_valid_json(df[col].iloc[0]):\n",
    "        # Parse the column\n",
    "        df[f'{col}_Key'] = df[col].apply(lambda x: json.loads(x)['key'] if is_valid_json(x) else None)\n",
    "        df[f'{col}_Value'] = df[col].apply(lambda x: json.loads(x)['value'] if is_valid_json(x) else None)\n",
    "        df = df.drop(columns=col)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   ProductID              90 non-null     object \n",
      " 1   ProductName            90 non-null     object \n",
      " 2   Category               90 non-null     object \n",
      " 3   QuantitySold           90 non-null     float64\n",
      " 4   SalesDate              90 non-null     object \n",
      " 5   UnitPrice              90 non-null     float64\n",
      " 6   Revenue                90 non-null     float64\n",
      " 7   Channel                90 non-null     object \n",
      " 8   Weekday                90 non-null     object \n",
      " 9   Month                  90 non-null     float64\n",
      " 10  Quarter                90 non-null     float64\n",
      " 11  Year                   90 non-null     float64\n",
      " 12  Holiday                90 non-null     object \n",
      " 13  EconomicIndicators     90 non-null     object \n",
      " 14  MarketTrends           90 non-null     object \n",
      " 15  CompetitorPricing      90 non-null     float64\n",
      " 16  Promotions             90 non-null     object \n",
      " 17  WeatherConditions      90 non-null     object \n",
      " 18  PoliticalEvents        90 non-null     object \n",
      " 19  StockLevels            90 non-null     float64\n",
      " 20  LeadTime               90 non-null     float64\n",
      " 21  SupplierPerformance    90 non-null     float64\n",
      " 22  CustomerSegment        90 non-null     object \n",
      " 23  PurchaseHistory        90 non-null     object \n",
      " 24  ProductRatingsReviews  90 non-null     float64\n",
      " 25  Features               90 non-null     object \n",
      " 26  LaunchDate             90 non-null     object \n",
      " 27  LifeCycleStage         90 non-null     object \n",
      "dtypes: float64(11), object(17)\n",
      "memory usage: 22.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuantitySold</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>CompetitorPricing</th>\n",
       "      <th>StockLevels</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>SupplierPerformance</th>\n",
       "      <th>ProductRatingsReviews</th>\n",
       "      <th>EconomicIndicators_Value</th>\n",
       "      <th>MarketTrends_Value</th>\n",
       "      <th>PurchaseHistory_Value</th>\n",
       "      <th>Features_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1767.49</td>\n",
       "      <td>8297.32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>193.36</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4404.0</td>\n",
       "      <td>431973732.0</td>\n",
       "      <td>23638724.0</td>\n",
       "      <td>567049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>695.98</td>\n",
       "      <td>4474.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>449.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1200.98</td>\n",
       "      <td>2609.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1135.67</td>\n",
       "      <td>75.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5077492.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>738250840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1893.33</td>\n",
       "      <td>9228.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>192.18</td>\n",
       "      <td>92.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.17</td>\n",
       "      <td>7499883.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>8740.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1434.96</td>\n",
       "      <td>6755.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>587.92</td>\n",
       "      <td>73.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.41</td>\n",
       "      <td>36168.0</td>\n",
       "      <td>9845051.0</td>\n",
       "      <td>72771.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuantitySold  UnitPrice  Revenue  Month  Quarter    Year  \\\n",
       "0           2.0    1767.49  8297.32    5.0      3.0  2021.0   \n",
       "1           6.0     695.98  4474.01    3.0      1.0  2021.0   \n",
       "2          10.0    1200.98  2609.65    9.0      4.0  2021.0   \n",
       "3          29.0    1893.33  9228.89    7.0      2.0  2022.0   \n",
       "4          41.0    1434.96  6755.29    5.0      4.0  2022.0   \n",
       "\n",
       "   CompetitorPricing  StockLevels  LeadTime  SupplierPerformance  \\\n",
       "0             193.36         13.0      28.0                 0.76   \n",
       "1             449.00         19.0      29.0                  NaN   \n",
       "2            1135.67         75.0      16.0                 0.87   \n",
       "3             192.18         92.0      26.0                 0.72   \n",
       "4             587.92         73.0      21.0                 0.96   \n",
       "\n",
       "   ProductRatingsReviews  EconomicIndicators_Value  MarketTrends_Value  \\\n",
       "0                   2.27                    4404.0         431973732.0   \n",
       "1                   4.67                       9.0                 NaN   \n",
       "2                   3.70                 5077492.0                95.0   \n",
       "3                   1.17                 7499883.0               434.0   \n",
       "4                   3.41                   36168.0           9845051.0   \n",
       "\n",
       "   PurchaseHistory_Value  Features_Value  \n",
       "0             23638724.0        567049.0  \n",
       "1                    7.0             NaN  \n",
       "2                   35.0     738250840.0  \n",
       "3                 8740.0             NaN  \n",
       "4                72771.0            89.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical = df.select_dtypes(include=[np.number])\n",
    "df_numerical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill nan values with deep learning prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 712.6751 - val_loss: 836.7580\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 696.6111 - val_loss: 819.6070\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 680.3755 - val_loss: 800.4968\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 662.6032 - val_loss: 778.3195\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 643.2981 - val_loss: 752.5042\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 619.1972 - val_loss: 722.6904\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 592.8333 - val_loss: 688.7291\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 560.2492 - val_loss: 649.7708\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 524.8484 - val_loss: 605.0172\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 481.7845 - val_loss: 554.5726\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 437.4900 - val_loss: 499.7239\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 387.2436 - val_loss: 442.7097\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 337.1721 - val_loss: 385.0589\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 288.6414 - val_loss: 331.4597\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 244.9689 - val_loss: 286.7166\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 206.8682 - val_loss: 256.3281\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 189.7524 - val_loss: 240.6703\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 181.0250 - val_loss: 236.0917\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 183.8505 - val_loss: 235.8625\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 180.6898 - val_loss: 234.6898\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 173.2348 - val_loss: 234.4412\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 164.7979 - val_loss: 236.5001\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 158.7360 - val_loss: 239.8766\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 155.0465 - val_loss: 243.4198\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 151.4122 - val_loss: 244.9657\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 148.6145 - val_loss: 245.8712\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 146.1395 - val_loss: 244.4734\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 143.1591 - val_loss: 242.0904\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 140.5664 - val_loss: 239.6332\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 138.3671 - val_loss: 239.0912\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 136.3831 - val_loss: 239.1306\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 1449377.8750 - val_loss: 1753891.6250\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1448591.5000 - val_loss: 1752957.3750\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1447863.5000 - val_loss: 1751990.0000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1447089.5000 - val_loss: 1750893.2500\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1446214.3750 - val_loss: 1749649.7500\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1445206.5000 - val_loss: 1748219.2500\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1443961.5000 - val_loss: 1746582.1250\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1442549.1250 - val_loss: 1744653.7500\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1440855.1250 - val_loss: 1742394.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1438818.1250 - val_loss: 1739734.0000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1436384.0000 - val_loss: 1736596.2500\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1433589.3750 - val_loss: 1732842.3750\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1430126.0000 - val_loss: 1728442.1250\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1426000.8750 - val_loss: 1723288.7500\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1421125.5000 - val_loss: 1717256.1250\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1415536.3750 - val_loss: 1710279.8750\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1408765.1250 - val_loss: 1702267.5000\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1401145.5000 - val_loss: 1692964.8750\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1392134.5000 - val_loss: 1682315.0000\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1381950.6250 - val_loss: 1670218.5000\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1370104.5000 - val_loss: 1656564.7500\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1356584.8750 - val_loss: 1641174.5000\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1341245.3750 - val_loss: 1623833.2500\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1324386.7500 - val_loss: 1604277.6250\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1304305.3750 - val_loss: 1582256.1250\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1282150.7500 - val_loss: 1557621.2500\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1257740.3750 - val_loss: 1530210.1250\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1229471.0000 - val_loss: 1499714.1250\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1199376.7500 - val_loss: 1466126.5000\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1165806.1250 - val_loss: 1429720.1250\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1127829.6250 - val_loss: 1390307.7500\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1087786.3750 - val_loss: 1347287.5000\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1045347.0000 - val_loss: 1300482.6250\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 997946.3125 - val_loss: 1250980.3750\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 947709.3125 - val_loss: 1199176.6250\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 895578.9375 - val_loss: 1145116.2500\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 841405.0625 - val_loss: 1088585.1250\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 786195.8750 - val_loss: 1028732.4375\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 728023.0625 - val_loss: 967285.1250\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 671048.4375 - val_loss: 904784.2500\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 609228.7500 - val_loss: 842064.7500\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 551642.3125 - val_loss: 779909.0000\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 495346.6562 - val_loss: 719764.0625\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 441118.7500 - val_loss: 661718.3125\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 391823.1250 - val_loss: 606258.7500\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 349033.9688 - val_loss: 555914.2500\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 307605.2188 - val_loss: 510561.0000\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 275660.8438 - val_loss: 469839.8750\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 248911.1719 - val_loss: 433346.6250\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 227381.9375 - val_loss: 403478.8750\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 211790.1562 - val_loss: 380019.7188\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 201264.4375 - val_loss: 362030.2812\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 193255.6250 - val_loss: 348282.0000\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 188138.5156 - val_loss: 338222.1250\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 184643.0625 - val_loss: 331763.9375\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 182526.9375 - val_loss: 327154.1250\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 179181.6719 - val_loss: 324592.0000\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 175820.1094 - val_loss: 322810.9688\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 173406.0625 - val_loss: 321508.5312\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 170083.1562 - val_loss: 320439.1250\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 167316.7344 - val_loss: 321107.0938\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 165150.5781 - val_loss: 322242.1250\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 162589.8438 - val_loss: 323967.1875\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 160568.1406 - val_loss: 325149.7500\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 158678.4844 - val_loss: 325235.2188\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 157146.4375 - val_loss: 324418.9375\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 155402.4688 - val_loss: 324125.6250\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 153718.5156 - val_loss: 324087.6875\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 152149.9531 - val_loss: 323869.8750\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 150863.7812 - val_loss: 323337.4062\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 31988508.0000 - val_loss: 42895020.0000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31984292.0000 - val_loss: 42889588.0000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 31980324.0000 - val_loss: 42884320.0000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 31976392.0000 - val_loss: 42878840.0000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31972280.0000 - val_loss: 42872784.0000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 31967268.0000 - val_loss: 42865720.0000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31961640.0000 - val_loss: 42857432.0000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 31954748.0000 - val_loss: 42847668.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31946638.0000 - val_loss: 42835932.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 31937112.0000 - val_loss: 42821992.0000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31925038.0000 - val_loss: 42805528.0000\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31911118.0000 - val_loss: 42786032.0000\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 31895368.0000 - val_loss: 42762900.0000\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 31875900.0000 - val_loss: 42735856.0000\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31853504.0000 - val_loss: 42704324.0000\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 31826568.0000 - val_loss: 42667156.0000\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31794816.0000 - val_loss: 42624288.0000\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 31757650.0000 - val_loss: 42574580.0000\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 31714486.0000 - val_loss: 42516868.0000\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 31665928.0000 - val_loss: 42449936.0000\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31605194.0000 - val_loss: 42373156.0000\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 31537864.0000 - val_loss: 42284984.0000\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 31459812.0000 - val_loss: 42186048.0000\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 31374610.0000 - val_loss: 42073504.0000\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 31272960.0000 - val_loss: 41946424.0000\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31159370.0000 - val_loss: 41803052.0000\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31028750.0000 - val_loss: 41642660.0000\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 30880886.0000 - val_loss: 41461252.0000\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 30718574.0000 - val_loss: 41259048.0000\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 30522262.0000 - val_loss: 41037392.0000\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 30329820.0000 - val_loss: 40789152.0000\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 30099442.0000 - val_loss: 40511692.0000\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 29840968.0000 - val_loss: 40208452.0000\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 29569298.0000 - val_loss: 39876388.0000\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 29254702.0000 - val_loss: 39516020.0000\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 28933890.0000 - val_loss: 39122912.0000\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 28558780.0000 - val_loss: 38699672.0000\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 28164532.0000 - val_loss: 38238720.0000\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 27757122.0000 - val_loss: 37735872.0000\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 27284426.0000 - val_loss: 37196620.0000\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26801126.0000 - val_loss: 36628768.0000\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26258626.0000 - val_loss: 36029136.0000\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 25709714.0000 - val_loss: 35392176.0000\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 25118606.0000 - val_loss: 34721420.0000\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 24499060.0000 - val_loss: 34010448.0000\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 23837706.0000 - val_loss: 33254770.0000\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 23173638.0000 - val_loss: 32449352.0000\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 22430554.0000 - val_loss: 31618570.0000\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 21687940.0000 - val_loss: 30735416.0000\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 20884978.0000 - val_loss: 29818396.0000\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 20037580.0000 - val_loss: 28894106.0000\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 19238052.0000 - val_loss: 27955394.0000\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 18380696.0000 - val_loss: 26976344.0000\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 17527006.0000 - val_loss: 25952556.0000\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 16616455.0000 - val_loss: 24905970.0000\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 15738699.0000 - val_loss: 23858130.0000\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 14829330.0000 - val_loss: 22822264.0000\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 13981359.0000 - val_loss: 21807228.0000\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 13102481.0000 - val_loss: 20800184.0000\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 12287130.0000 - val_loss: 19787346.0000\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11444981.0000 - val_loss: 18824392.0000\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 10695372.0000 - val_loss: 17908266.0000\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9979864.0000 - val_loss: 17003780.0000\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 9312125.0000 - val_loss: 16149006.0000\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 8707531.0000 - val_loss: 15390485.0000\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 8158352.0000 - val_loss: 14708448.0000\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 7700587.5000 - val_loss: 14068238.0000\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 7246727.0000 - val_loss: 13500095.0000\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 6914098.0000 - val_loss: 12999604.0000\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6588748.5000 - val_loss: 12594391.0000\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6331990.0000 - val_loss: 12237513.0000\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6117662.5000 - val_loss: 11942982.0000\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5941216.0000 - val_loss: 11704462.0000\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5820653.5000 - val_loss: 11530530.0000\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5676610.0000 - val_loss: 11391847.0000\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5571959.5000 - val_loss: 11268251.0000\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5491722.5000 - val_loss: 11177764.0000\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 5418882.5000 - val_loss: 11119412.0000\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5339148.5000 - val_loss: 11112000.0000\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5267898.0000 - val_loss: 11133192.0000\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5225925.5000 - val_loss: 11163515.0000\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5150429.5000 - val_loss: 11181012.0000\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5095757.5000 - val_loss: 11190084.0000\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5043519.0000 - val_loss: 11201220.0000\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4987525.5000 - val_loss: 11208228.0000\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4939200.0000 - val_loss: 11223189.0000\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4892215.0000 - val_loss: 11239531.0000\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4844675.5000 - val_loss: 11253961.0000\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 4801238.0000 - val_loss: 11258539.0000\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 49.8611 - val_loss: 51.2771\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 46.6936 - val_loss: 48.1163\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 43.8727 - val_loss: 44.7004\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 41.2010 - val_loss: 41.0594\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 38.0257 - val_loss: 37.1375\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 34.6118 - val_loss: 32.9013\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 31.0413 - val_loss: 28.3916\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 27.3254 - val_loss: 23.8203\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 23.6095 - val_loss: 19.4803\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 20.1835 - val_loss: 15.8286\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 18.0194 - val_loss: 13.3210\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 15.9217 - val_loss: 12.0528\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 15.6165 - val_loss: 11.6743\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 15.4248 - val_loss: 11.6558\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 15.0165 - val_loss: 11.5467\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 14.3470 - val_loss: 11.4233\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 13.7984 - val_loss: 11.3375\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 13.2003 - val_loss: 11.1988\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 12.7275 - val_loss: 11.1051\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 12.3019 - val_loss: 11.0945\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11.9082 - val_loss: 11.0895\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 11.5549 - val_loss: 11.0154\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11.2007 - val_loss: 10.9981\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 10.9188 - val_loss: 11.0285\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 10.5748 - val_loss: 11.0212\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 10.2636 - val_loss: 11.0195\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 10.0140 - val_loss: 11.0452\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.7197 - val_loss: 11.0762\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.4871 - val_loss: 11.1411\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.2582 - val_loss: 11.2710\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.0533 - val_loss: 11.4142\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.8268 - val_loss: 11.5840\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.6499 - val_loss: 11.7361\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 54ms/step - loss: 6.2838 - val_loss: 5.5042\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4.8689 - val_loss: 4.3727\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.7452 - val_loss: 3.4544\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.8179 - val_loss: 2.7465\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.0740 - val_loss: 2.2371\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5462 - val_loss: 1.9743\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2461 - val_loss: 1.9262\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1456 - val_loss: 1.9662\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1328 - val_loss: 1.9788\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0967 - val_loss: 1.9602\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0014 - val_loss: 1.8913\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8868 - val_loss: 1.8160\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7927 - val_loss: 1.7752\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7353 - val_loss: 1.7772\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7110 - val_loss: 1.7871\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6918 - val_loss: 1.8066\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6649 - val_loss: 1.8320\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6311 - val_loss: 1.8810\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5989 - val_loss: 1.9568\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5679 - val_loss: 2.0518\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5558 - val_loss: 2.1430\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5481 - val_loss: 2.2001\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5279 - val_loss: 2.2297\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 4082342.2500 - val_loss: 4084382.2500\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4081505.0000 - val_loss: 4083618.7500\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4080637.0000 - val_loss: 4082735.5000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4079681.7500 - val_loss: 4081699.5000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4078554.2500 - val_loss: 4080451.5000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4077223.5000 - val_loss: 4078929.0000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4075589.0000 - val_loss: 4077071.5000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4073522.7500 - val_loss: 4074769.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4070996.5000 - val_loss: 4071932.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4067937.0000 - val_loss: 4068476.5000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 4064136.0000 - val_loss: 4064311.0000\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4059473.0000 - val_loss: 4059322.7500\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4053952.0000 - val_loss: 4053399.0000\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4047261.7500 - val_loss: 4046363.0000\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4039459.5000 - val_loss: 4038036.0000\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4030073.2500 - val_loss: 4028250.7500\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4018862.2500 - val_loss: 4016839.0000\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 4005825.0000 - val_loss: 4003590.7500\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3990551.5000 - val_loss: 3988273.7500\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3972888.5000 - val_loss: 3970708.0000\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3952508.0000 - val_loss: 3950752.5000\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3928910.7500 - val_loss: 3927928.5000\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3902160.0000 - val_loss: 3901885.2500\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3871844.0000 - val_loss: 3872477.2500\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3837020.5000 - val_loss: 3839624.5000\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3797998.7500 - val_loss: 3802815.0000\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3754390.2500 - val_loss: 3761562.7500\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3705454.5000 - val_loss: 3716009.0000\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3651115.5000 - val_loss: 3665633.2500\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3590694.2500 - val_loss: 3610065.5000\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3524325.7500 - val_loss: 3549384.2500\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3451145.5000 - val_loss: 3483278.2500\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3371476.5000 - val_loss: 3411689.5000\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3285356.5000 - val_loss: 3333901.2500\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3191209.2500 - val_loss: 3249976.5000\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3090905.0000 - val_loss: 3160602.0000\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2981459.0000 - val_loss: 3064895.0000\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2865225.5000 - val_loss: 2962456.2500\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2741369.0000 - val_loss: 2853461.7500\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2611787.0000 - val_loss: 2738534.0000\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2474520.7500 - val_loss: 2617752.0000\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2329848.0000 - val_loss: 2490520.5000\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2182698.7500 - val_loss: 2358030.7500\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2029036.8750 - val_loss: 2221287.7500\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1872528.6250 - val_loss: 2081025.7500\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1712691.2500 - val_loss: 1938038.8750\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1553489.1250 - val_loss: 1793538.0000\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1393203.5000 - val_loss: 1648725.2500\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1236077.3750 - val_loss: 1504382.1250\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1083103.6250 - val_loss: 1361616.3750\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 936100.8750 - val_loss: 1222949.3750\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 797167.6875 - val_loss: 1090299.6250\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 669391.6875 - val_loss: 963934.2500\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 552299.2500 - val_loss: 846220.6875\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 448830.7500 - val_loss: 736913.6875\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 358366.3750 - val_loss: 636888.4375\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 284476.8750 - val_loss: 546367.1875\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 222432.9844 - val_loss: 468327.5625\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 173699.3438 - val_loss: 402220.1562\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 139470.3438 - val_loss: 346877.6562\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 112225.0000 - val_loss: 301493.6250\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 96916.3672 - val_loss: 264195.9375\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 84988.8672 - val_loss: 235638.4375\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 77229.5938 - val_loss: 213030.5938\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 72801.9531 - val_loss: 195059.9844\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 70165.9062 - val_loss: 180932.5156\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 67337.0156 - val_loss: 170639.4688\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 64887.0078 - val_loss: 163368.4844\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 62519.7656 - val_loss: 158663.5625\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 59971.5820 - val_loss: 155553.4844\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 57668.8242 - val_loss: 153598.0000\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 55011.7773 - val_loss: 151533.5156\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 53155.5781 - val_loss: 150114.6875\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 51159.5039 - val_loss: 148996.6875\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 49428.0938 - val_loss: 147788.9219\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 47812.9805 - val_loss: 147572.3906\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 46351.8828 - val_loss: 147287.9062\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 45158.2500 - val_loss: 146944.2500\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 44126.3477 - val_loss: 146687.3906\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 43091.2383 - val_loss: 146145.5469\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 42076.9688 - val_loss: 145683.3594\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 41328.2148 - val_loss: 144722.4844\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 40550.2891 - val_loss: 143625.8281\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 39882.9023 - val_loss: 141852.4062\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 39131.5664 - val_loss: 140052.8438\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 38413.4531 - val_loss: 138318.4062\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 37808.5156 - val_loss: 136325.0625\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 37067.6367 - val_loss: 134469.0625\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 36517.8164 - val_loss: 132604.1875\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 35929.5156 - val_loss: 130761.8594\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 35354.8125 - val_loss: 129233.3203\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 34764.1719 - val_loss: 127612.4844\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 34267.2969 - val_loss: 126495.1406\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 33782.9375 - val_loss: 125850.6797\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 33307.8281 - val_loss: 125852.0703\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 32933.3633 - val_loss: 126076.0938\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 32387.3262 - val_loss: 126140.2344\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31969.0898 - val_loss: 126065.4297\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31537.1113 - val_loss: 125403.4141\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 31200.0137 - val_loss: 124107.7891\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 30793.7598 - val_loss: 122841.3047\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 30438.7285 - val_loss: 121059.0156\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 30117.3477 - val_loss: 119004.8906\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 29748.7988 - val_loss: 117190.5000\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 29380.4863 - val_loss: 115908.7578\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 28957.3398 - val_loss: 114687.6562\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 28595.2520 - val_loss: 113904.7891\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 28184.5312 - val_loss: 113333.5938\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 27862.5762 - val_loss: 112818.4062\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 27460.6113 - val_loss: 112384.6562\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 27128.2539 - val_loss: 111867.6328\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26776.5566 - val_loss: 111203.7188\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26468.7031 - val_loss: 110613.5781\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26084.3535 - val_loss: 110245.3594\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 25778.4121 - val_loss: 110409.3047\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 25489.3887 - val_loss: 110389.8906\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 25254.1074 - val_loss: 110675.2188\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 24968.7949 - val_loss: 110926.2344\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 24729.3223 - val_loss: 111215.6250\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 24545.8848 - val_loss: 111059.5000\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 24286.1504 - val_loss: 110930.0469\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 24028.4492 - val_loss: 111142.4844\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 23857.0117 - val_loss: 111262.8828\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 23597.6191 - val_loss: 110934.4219\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 58ms/step - loss: 1287541.7500 - val_loss: 940022.2500\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1286783.0000 - val_loss: 939399.1250\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1285999.0000 - val_loss: 938726.5625\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1285102.2500 - val_loss: 937943.4375\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1284147.3750 - val_loss: 937035.7500\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1282929.5000 - val_loss: 935978.3125\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1281516.6250 - val_loss: 934726.7500\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1279795.1250 - val_loss: 933241.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1277733.5000 - val_loss: 931484.1875\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1275238.3750 - val_loss: 929396.7500\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1272283.7500 - val_loss: 926909.7500\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1268941.2500 - val_loss: 923972.9375\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1264700.7500 - val_loss: 920556.2500\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1259955.8750 - val_loss: 916567.9375\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1254169.5000 - val_loss: 911931.3750\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1247697.5000 - val_loss: 906564.5625\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1239438.7500 - val_loss: 900411.0000\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1230624.5000 - val_loss: 893298.9375\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1220201.2500 - val_loss: 885148.2500\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1207902.0000 - val_loss: 875879.2500\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1194089.3750 - val_loss: 865455.2500\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1178510.3750 - val_loss: 853722.9375\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1161044.1250 - val_loss: 840471.5625\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1141356.5000 - val_loss: 825778.3125\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1117883.5000 - val_loss: 809552.5625\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1093162.5000 - val_loss: 791584.2500\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1066385.5000 - val_loss: 771853.2500\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1036883.8750 - val_loss: 750540.0625\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1005029.6875 - val_loss: 727902.1250\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 969788.2500 - val_loss: 704269.7500\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 933988.7500 - val_loss: 678871.3125\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 895032.3750 - val_loss: 652480.1250\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 852657.5625 - val_loss: 625415.2500\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 811283.8125 - val_loss: 596765.0000\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 764401.0625 - val_loss: 567917.8125\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 717936.8750 - val_loss: 538277.5000\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 670729.0625 - val_loss: 508488.0625\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 621894.3125 - val_loss: 479617.6562\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 571564.2500 - val_loss: 451777.5625\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 527383.6250 - val_loss: 425791.4688\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 479909.0625 - val_loss: 403054.5000\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 440165.4375 - val_loss: 383128.3750\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 401652.2500 - val_loss: 366358.7500\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 367691.5938 - val_loss: 354011.8750\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 336088.5938 - val_loss: 346744.8750\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 311516.5625 - val_loss: 343986.3438\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 289919.4375 - val_loss: 344752.3438\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 276869.3750 - val_loss: 348607.7812\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 264623.6250 - val_loss: 354486.1250\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 259705.4375 - val_loss: 362791.3750\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 253078.0625 - val_loss: 371000.5938\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 248380.4219 - val_loss: 377599.1875\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 246198.5000 - val_loss: 384206.3750\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 243654.1094 - val_loss: 390389.8750\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 240897.5781 - val_loss: 395795.0625\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 238168.6406 - val_loss: 399612.6250\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 51ms/step - loss: 2998.2483 - val_loss: 3865.6680\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2960.2437 - val_loss: 3834.0869\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2928.7979 - val_loss: 3801.4531\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2896.8225 - val_loss: 3764.8411\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2860.0947 - val_loss: 3724.2412\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2817.7349 - val_loss: 3677.0908\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2770.6113 - val_loss: 3621.1123\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2715.1252 - val_loss: 3555.5222\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2649.6550 - val_loss: 3478.5137\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2573.6514 - val_loss: 3389.2986\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2484.9202 - val_loss: 3287.1768\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2386.4568 - val_loss: 3171.6680\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2269.8440 - val_loss: 3044.5500\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2145.7405 - val_loss: 2902.5476\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2005.5553 - val_loss: 2745.8740\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1851.5756 - val_loss: 2575.3745\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1688.0299 - val_loss: 2392.6885\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1516.8060 - val_loss: 2205.5371\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1344.4012 - val_loss: 2018.9116\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1183.0099 - val_loss: 1835.7446\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1020.9583 - val_loss: 1662.0956\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 890.4209 - val_loss: 1509.1312\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 789.7352 - val_loss: 1392.3552\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 716.8396 - val_loss: 1315.9427\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 674.4894 - val_loss: 1268.8547\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 651.4596 - val_loss: 1240.3983\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 652.0587 - val_loss: 1219.0015\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 643.0181 - val_loss: 1203.1024\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 634.8372 - val_loss: 1197.1206\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 622.9820 - val_loss: 1193.0343\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 606.0214 - val_loss: 1194.2175\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 592.0833 - val_loss: 1201.2537\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 579.7222 - val_loss: 1210.0361\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 570.7120 - val_loss: 1214.7101\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 565.8265 - val_loss: 1223.5024\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 560.5132 - val_loss: 1227.4449\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 559.0575 - val_loss: 1228.8779\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 551.4792 - val_loss: 1218.2993\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 542.0198 - val_loss: 1212.7566\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 532.1993 - val_loss: 1205.5482\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 323.5614 - val_loss: 257.2166\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 313.6649 - val_loss: 246.8492\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 302.2245 - val_loss: 235.2038\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 289.5086 - val_loss: 222.4769\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 274.3112 - val_loss: 208.2534\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 257.3533 - val_loss: 192.3383\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 238.0330 - val_loss: 174.7735\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 216.8545 - val_loss: 156.1226\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 192.4775 - val_loss: 137.1501\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 168.1893 - val_loss: 117.9140\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 143.9240 - val_loss: 100.1087\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 120.1645 - val_loss: 85.6519\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 102.1762 - val_loss: 76.0783\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 88.1730 - val_loss: 72.1520\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 79.8195 - val_loss: 73.3492\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 74.9287 - val_loss: 77.0975\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 75.5891 - val_loss: 81.4427\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 75.4707 - val_loss: 83.6479\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 73.9211 - val_loss: 83.3350\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 70.7703 - val_loss: 80.2954\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 67.0732 - val_loss: 76.5385\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 63.4938 - val_loss: 73.4247\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 61.7684 - val_loss: 70.6955\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 61.0743 - val_loss: 69.2796\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 59.4813 - val_loss: 69.4102\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 58.4508 - val_loss: 69.6472\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 57.4813 - val_loss: 70.1825\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 56.1475 - val_loss: 71.0054\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 55.2942 - val_loss: 72.1996\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 54.4647 - val_loss: 73.6359\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 53.6007 - val_loss: 74.9219\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 53.0334 - val_loss: 75.6058\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 52.4357 - val_loss: 75.3777\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 51.7029 - val_loss: 74.3149\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 57ms/step - loss: 0.3310 - val_loss: 0.1427\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1435 - val_loss: 0.1459\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1224 - val_loss: 0.1473\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0943 - val_loss: 0.1029\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0526 - val_loss: 0.0658\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.0552\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0281 - val_loss: 0.0519\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0245 - val_loss: 0.0534\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0187 - val_loss: 0.0598\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0159 - val_loss: 0.0673\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0155 - val_loss: 0.0694\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0136 - val_loss: 0.0636\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0558\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0526\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0538\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0581\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0630\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 51ms/step - loss: 10.6513 - val_loss: 10.0034\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.1623 - val_loss: 8.7554\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.9561 - val_loss: 7.5051\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.6686 - val_loss: 6.2476\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5.3623 - val_loss: 4.9581\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4.0775 - val_loss: 3.7055\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.9350 - val_loss: 2.6286\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0129 - val_loss: 1.9050\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.5134 - val_loss: 1.6025\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4482 - val_loss: 1.6089\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6018 - val_loss: 1.6379\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.5807 - val_loss: 1.5556\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3669 - val_loss: 1.4585\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1651 - val_loss: 1.4378\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0303 - val_loss: 1.4831\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9751 - val_loss: 1.5447\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9761 - val_loss: 1.6021\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9816 - val_loss: 1.5949\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9227 - val_loss: 1.5125\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8469 - val_loss: 1.4217\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7860 - val_loss: 1.3549\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7586 - val_loss: 1.3230\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7480 - val_loss: 1.3188\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7243 - val_loss: 1.3278\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6922 - val_loss: 1.3441\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6586 - val_loss: 1.3658\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6347 - val_loss: 1.3941\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6107 - val_loss: 1.4065\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5865 - val_loss: 1.4108\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5676 - val_loss: 1.4103\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5479 - val_loss: 1.4145\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5263 - val_loss: 1.4152\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5071 - val_loss: 1.4069\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 57355242378887168.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 57355242378887168.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 57355242378887168.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 57355242378887168.0000 - val_loss: 40795227170013184.0000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 57355238083919872.0000 - val_loss: 40795227170013184.0000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 71ms/step - loss: 51444663004954624.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 51444667299921920.0000 - val_loss: 50935915538808832.0000\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 51ms/step - loss: 26342995078938624.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342997226422272.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342995078938624.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342995078938624.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 26342995078938624.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342997226422272.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342992931454976.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342997226422272.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342992931454976.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342995078938624.0000 - val_loss: 3596000828588032.0000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342992931454976.0000 - val_loss: 3596000560152576.0000\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26342997226422272.0000 - val_loss: 3596000560152576.0000\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342995078938624.0000 - val_loss: 3596000560152576.0000\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342995078938624.0000 - val_loss: 3596000560152576.0000\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 26342997226422272.0000 - val_loss: 3596000560152576.0000\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342997226422272.0000 - val_loss: 3596000560152576.0000\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342995078938624.0000 - val_loss: 3596000291717120.0000\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26342992931454976.0000 - val_loss: 3596000291717120.0000\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 26342992931454976.0000 - val_loss: 3596000291717120.0000\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26342992931454976.0000 - val_loss: 3596000023281664.0000\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 26342992931454976.0000 - val_loss: 3595999754846208.0000\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 26342990783971328.0000 - val_loss: 3595999754846208.0000\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 26342990783971328.0000 - val_loss: 3595998949539840.0000\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 26342988636487680.0000 - val_loss: 3595998949539840.0000\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26342990783971328.0000 - val_loss: 3595998949539840.0000\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 26342988636487680.0000 - val_loss: 3595998144233472.0000\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 26342988636487680.0000 - val_loss: 3595998144233472.0000\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26342986489004032.0000 - val_loss: 3595997338927104.0000\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342984341520384.0000 - val_loss: 3595996802056192.0000\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342984341520384.0000 - val_loss: 3595996265185280.0000\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342984341520384.0000 - val_loss: 3595995728314368.0000\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 26342977899069440.0000 - val_loss: 3595994654572544.0000\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342977899069440.0000 - val_loss: 3595994117701632.0000\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342973604102144.0000 - val_loss: 3595993312395264.0000\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342967161651200.0000 - val_loss: 3595992238653440.0000\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342967161651200.0000 - val_loss: 3595990896476160.0000\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342962866683904.0000 - val_loss: 3595989554298880.0000\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342958571716608.0000 - val_loss: 3595988480557056.0000\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 26342956424232960.0000 - val_loss: 3595987138379776.0000\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 26342947834298368.0000 - val_loss: 3595985796202496.0000\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 26342943539331072.0000 - val_loss: 3595983648718848.0000\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342934949396480.0000 - val_loss: 3595981769670656.0000\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26342928506945536.0000 - val_loss: 3595979622187008.0000\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26342922064494592.0000 - val_loss: 3595978011574272.0000\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342911327076352.0000 - val_loss: 3595975864090624.0000\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342900589658112.0000 - val_loss: 3595973179736064.0000\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342894147207168.0000 - val_loss: 3595971032252416.0000\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342885557272576.0000 - val_loss: 3595968079462400.0000\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342872672370688.0000 - val_loss: 3595964589801472.0000\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342859787468800.0000 - val_loss: 3595961905446912.0000\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26342849050050560.0000 - val_loss: 3595958147350528.0000\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342838312632320.0000 - val_loss: 3595954389254144.0000\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342816837795840.0000 - val_loss: 3595951168028672.0000\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342801805410304.0000 - val_loss: 3595947409932288.0000\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342788920508416.0000 - val_loss: 3595943114964992.0000\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26342769593155584.0000 - val_loss: 3595938551562240.0000\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342752413286400.0000 - val_loss: 3595933719724032.0000\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342728790966272.0000 - val_loss: 3595928887885824.0000\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342709463613440.0000 - val_loss: 3595923519176704.0000\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342681546326016.0000 - val_loss: 3595917613596672.0000\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342657924005888.0000 - val_loss: 3595911171145728.0000\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342632154202112.0000 - val_loss: 3595904997130240.0000\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342606384398336.0000 - val_loss: 3595898823114752.0000\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342582762078208.0000 - val_loss: 3595892380663808.0000\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342546254856192.0000 - val_loss: 3595885938212864.0000\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342516190085120.0000 - val_loss: 3595877885149184.0000\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342481830346752.0000 - val_loss: 3595868758343680.0000\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342432438222848.0000 - val_loss: 3595859631538176.0000\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342400225968128.0000 - val_loss: 3595849430990848.0000\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26342355128811520.0000 - val_loss: 3595840035749888.0000\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342312179138560.0000 - val_loss: 3595830640508928.0000\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342273524432896.0000 - val_loss: 3595820976832512.0000\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26342217689858048.0000 - val_loss: 3595811581591552.0000\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342172592701440.0000 - val_loss: 3595799770431488.0000\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342114610642944.0000 - val_loss: 3595787422400512.0000\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26342065218519040.0000 - val_loss: 3595774269063168.0000\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26341992204075008.0000 - val_loss: 3595761384161280.0000\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26341947106918400.0000 - val_loss: 3595747962388480.0000\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26341874092474368.0000 - val_loss: 3595735614357504.0000\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 26341820405383168.0000 - val_loss: 3595722461020160.0000\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26341764570808320.0000 - val_loss: 3595709844553728.0000\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26341706588749824.0000 - val_loss: 3595696422780928.0000\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26341642164240384.0000 - val_loss: 3595684074749952.0000\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26341584182181888.0000 - val_loss: 3595670384541696.0000\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26341500430319616.0000 - val_loss: 3595655352156160.0000\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26341448890712064.0000 - val_loss: 3595638440722432.0000\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26341356548915200.0000 - val_loss: 3595622334595072.0000\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26341272797052928.0000 - val_loss: 3595605691596800.0000\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26341193340157952.0000 - val_loss: 3595588780163072.0000\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26341111735779328.0000 - val_loss: 3595571331858432.0000\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 26341012951531520.0000 - val_loss: 3595552272941056.0000\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340933494636544.0000 - val_loss: 3595529992798208.0000\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340836857872384.0000 - val_loss: 3595505833607168.0000\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26340712303820800.0000 - val_loss: 3595483553464320.0000\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340592044736512.0000 - val_loss: 3595460736450560.0000\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340469638168576.0000 - val_loss: 3595438187872256.0000\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340362263986176.0000 - val_loss: 3595411612762112.0000\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340248447352832.0000 - val_loss: 3595386379829248.0000\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26340106713432064.0000 - val_loss: 3595358730977280.0000\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26339986454347776.0000 - val_loss: 3595328934641664.0000\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26339825393074176.0000 - val_loss: 3595301285789696.0000\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26339707281473536.0000 - val_loss: 3595273100066816.0000\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26339556957618176.0000 - val_loss: 3595243035295744.0000\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26339408781246464.0000 - val_loss: 3595211091476480.0000\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26339245572489216.0000 - val_loss: 3595180489834496.0000\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26339114575986688.0000 - val_loss: 3595149619757056.0000\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 26338959957164032.0000 - val_loss: 3595119018115072.0000\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26338796748406784.0000 - val_loss: 3595088684908544.0000\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26338644277067776.0000 - val_loss: 3595058888572928.0000\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 26338468183408640.0000 - val_loss: 3595027481624576.0000\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26338296384716800.0000 - val_loss: 3594988290048000.0000\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26338103111188480.0000 - val_loss: 3594944266633216.0000\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26337896952758272.0000 - val_loss: 3594898364170240.0000\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26337628517302272.0000 - val_loss: 3594854340755456.0000\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26337458866094080.0000 - val_loss: 3594804948631552.0000\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26337190430638080.0000 - val_loss: 3594759046168576.0000\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26336919847698432.0000 - val_loss: 3594711264657408.0000\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26336713689268224.0000 - val_loss: 3594659993485312.0000\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26336346469564416.0000 - val_loss: 3594608453877760.0000\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26336159638487040.0000 - val_loss: 3594551277125632.0000\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 26335820336070656.0000 - val_loss: 3594498932211712.0000\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 26335551900614656.0000 - val_loss: 3594448197910528.0000\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26335236220518400.0000 - val_loss: 3594393168642048.0000\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26334961342611456.0000 - val_loss: 3594330623180800.0000\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26334690759671808.0000 - val_loss: 3594268077719552.0000\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26334308507582464.0000 - val_loss: 3594209021919232.0000\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26333967057682432.0000 - val_loss: 3594145939587072.0000\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26333679294873600.0000 - val_loss: 3594080441335808.0000\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 26333350729875456.0000 - val_loss: 3594018969616384.0000\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26332964182818816.0000 - val_loss: 3593954813542400.0000\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26332723664650240.0000 - val_loss: 3593882604404736.0000\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26332193236189184.0000 - val_loss: 3593814421798912.0000\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26331989225242624.0000 - val_loss: 3593737649258496.0000\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26331536106192896.0000 - val_loss: 3593668929781760.0000\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26331192508809216.0000 - val_loss: 3593605579014144.0000\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26330846763941888.0000 - val_loss: 3593544375730176.0000\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26330473101787136.0000 - val_loss: 3593487467413504.0000\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26330191781429248.0000 - val_loss: 3593430559096832.0000\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26329899723653120.0000 - val_loss: 3593370429554688.0000\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 26329549683818496.0000 - val_loss: 3593306273480704.0000\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26329184611598336.0000 - val_loss: 3593240506793984.0000\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26328914028658688.0000 - val_loss: 3593166150172672.0000\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26328497416830976.0000 - val_loss: 3593094746341376.0000\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26328145229512704.0000 - val_loss: 3593023610945536.0000\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26327722175234048.0000 - val_loss: 3592955428339712.0000\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26327322743275520.0000 - val_loss: 3592888051040256.0000\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26326970555957248.0000 - val_loss: 3592819868434432.0000\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26326579713933312.0000 - val_loss: 3592745511813120.0000\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26326193166876672.0000 - val_loss: 3592664712740864.0000\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26325800177369088.0000 - val_loss: 3592583645233152.0000\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26325392155475968.0000 - val_loss: 3592504188338176.0000\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26324891791785984.0000 - val_loss: 3592427952668672.0000\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26324505244729344.0000 - val_loss: 3592350643257344.0000\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26324058568130560.0000 - val_loss: 3592274139152384.0000\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26323622628950016.0000 - val_loss: 3592197903482880.0000\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26323244671827968.0000 - val_loss: 3592114151620608.0000\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26322810880131072.0000 - val_loss: 3592019662340096.0000\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26322265419284480.0000 - val_loss: 3591927857414144.0000\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26321767203078144.0000 - val_loss: 3591836857794560.0000\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26321258249453568.0000 - val_loss: 3591747737223168.0000\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26320888882266112.0000 - val_loss: 3591653516378112.0000\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26320321946583040.0000 - val_loss: 3591559295533056.0000\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26319815140442112.0000 - val_loss: 3591464269381632.0000\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26319254647209984.0000 - val_loss: 3591371122278400.0000\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26318689859010560.0000 - val_loss: 3591277975175168.0000\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26318236739960832.0000 - val_loss: 3591179459362816.0000\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26317637592023040.0000 - val_loss: 3591080406679552.0000\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 26317107163561984.0000 - val_loss: 3590975985287168.0000\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26316540227878912.0000 - val_loss: 3590867537362944.0000\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26315906720202752.0000 - val_loss: 3590752646987776.0000\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26315183018213376.0000 - val_loss: 3590619234566144.0000\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26314540920602624.0000 - val_loss: 3590475621597184.0000\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26313759236554752.0000 - val_loss: 3590337108901888.0000\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26312902390579200.0000 - val_loss: 3590200743690240.0000\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26312200163426304.0000 - val_loss: 3590052030447616.0000\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 26311356202352640.0000 - val_loss: 3589909759655936.0000\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26310499356377088.0000 - val_loss: 3589762925461504.0000\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26309610298146816.0000 - val_loss: 3589595153301504.0000\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26308716944949248.0000 - val_loss: 3589416912158720.0000\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26307812854333440.0000 - val_loss: 3589245650337792.0000\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26306599526072320.0000 - val_loss: 3589078415048704.0000\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26306026147938304.0000 - val_loss: 3588890241794048.0000\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26304799934775296.0000 - val_loss: 3588713342828544.0000\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26303608081350656.0000 - val_loss: 3588522485219328.0000\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26302519307141120.0000 - val_loss: 3588325453594624.0000\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26301436975382528.0000 - val_loss: 3588128153534464.0000\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26300386855878656.0000 - val_loss: 3587919310749696.0000\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26299278754316288.0000 - val_loss: 3587720400076800.0000\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26298052541153280.0000 - val_loss: 3587521220968448.0000\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 26296890752499712.0000 - val_loss: 3587319625940992.0000\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26295956597112832.0000 - val_loss: 3587110783156224.0000\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26294610124865536.0000 - val_loss: 3586910798741504.0000\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26293549267943424.0000 - val_loss: 3586701687521280.0000\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26292544245596160.0000 - val_loss: 3586493113171968.0000\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26291195625865216.0000 - val_loss: 3586279438548992.0000\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 26290184161067008.0000 - val_loss: 3586048852492288.0000\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26288708839800832.0000 - val_loss: 3585838667530240.0000\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 26287716702355456.0000 - val_loss: 3585627945697280.0000\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26286353050238976.0000 - val_loss: 3585416150122496.0000\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26285266423513088.0000 - val_loss: 3585179390050304.0000\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 70ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 50362077843292160.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 50362082138259456.0000 - val_loss: 4318790942720000.0000\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def fill_missing_with_dl(df, column):\n",
    "    # Define features and target\n",
    "    features = df.columns.difference([column]).tolist()\n",
    "    X = df[features]\n",
    "    y = df[column]\n",
    "    \n",
    "    # Handle missing values in features\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X_imputed[~y.isna()]\n",
    "    y_train = y[~y.isna()].values\n",
    "    X_predict = X_imputed[y.isna()]\n",
    "\n",
    "    # Normalize the input features\n",
    "    X_mean = X_train.mean(axis=0)\n",
    "    X_std = X_train.std(axis=0)\n",
    "    X_train = (X_train - X_mean) / X_std\n",
    "    X_predict = (X_predict - X_mean) / X_std\n",
    "\n",
    "    # Check if there's anything to predict\n",
    "    if not X_predict.size:\n",
    "        return df\n",
    "    \n",
    "    # Define the deep learning model\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Split training data for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, callbacks=[early_stopping], batch_size=32)\n",
    "    \n",
    "    # Predict the missing values\n",
    "    predicted_values = model.predict(X_predict)\n",
    "    \n",
    "    # Fill in the missing values in the original DataFrame\n",
    "    df.loc[df[column].isna(), column] = predicted_values.flatten()\n",
    "    \n",
    "    # Round each column to 1 decimal places after filling\n",
    "    df = df.round(1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "for column in df_numerical.columns.to_list():\n",
    "    df_numerical = fill_missing_with_dl(df_numerical, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantitySold                0\n",
       "UnitPrice                   0\n",
       "Revenue                     0\n",
       "Month                       0\n",
       "Quarter                     0\n",
       "Year                        0\n",
       "CompetitorPricing           0\n",
       "StockLevels                 0\n",
       "LeadTime                    0\n",
       "SupplierPerformance         0\n",
       "ProductRatingsReviews       0\n",
       "EconomicIndicators_Value    0\n",
       "MarketTrends_Value          0\n",
       "PurchaseHistory_Value       0\n",
       "Features_Value              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply numeric values standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuantitySold</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>CompetitorPricing</th>\n",
       "      <th>StockLevels</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>SupplierPerformance</th>\n",
       "      <th>ProductRatingsReviews</th>\n",
       "      <th>EconomicIndicators_Value</th>\n",
       "      <th>MarketTrends_Value</th>\n",
       "      <th>PurchaseHistory_Value</th>\n",
       "      <th>Features_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.356348</td>\n",
       "      <td>1.156912</td>\n",
       "      <td>-0.387940</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>-1.364285</td>\n",
       "      <td>-1.342198</td>\n",
       "      <td>1.500800</td>\n",
       "      <td>0.116193</td>\n",
       "      <td>-0.681875</td>\n",
       "      <td>-0.400524</td>\n",
       "      <td>1.771885</td>\n",
       "      <td>-0.123840</td>\n",
       "      <td>-0.356334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.839786</td>\n",
       "      <td>-0.197489</td>\n",
       "      <td>-0.989865</td>\n",
       "      <td>-1.268845</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>-0.889651</td>\n",
       "      <td>-1.120341</td>\n",
       "      <td>1.623585</td>\n",
       "      <td>1.339280</td>\n",
       "      <td>1.437943</td>\n",
       "      <td>-0.400545</td>\n",
       "      <td>-0.372641</td>\n",
       "      <td>-0.300062</td>\n",
       "      <td>-0.359465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.195256</td>\n",
       "      <td>-0.857951</td>\n",
       "      <td>0.815909</td>\n",
       "      <td>1.597522</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>0.385510</td>\n",
       "      <td>0.950325</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.727737</td>\n",
       "      <td>0.554685</td>\n",
       "      <td>-0.375744</td>\n",
       "      <td>-0.372641</td>\n",
       "      <td>-0.300062</td>\n",
       "      <td>3.716853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.614186</td>\n",
       "      <td>1.486931</td>\n",
       "      <td>0.213984</td>\n",
       "      <td>-0.313389</td>\n",
       "      <td>0.263317</td>\n",
       "      <td>-1.366513</td>\n",
       "      <td>1.578920</td>\n",
       "      <td>1.255230</td>\n",
       "      <td>-0.495350</td>\n",
       "      <td>-1.653457</td>\n",
       "      <td>-0.363912</td>\n",
       "      <td>-0.372639</td>\n",
       "      <td>-0.299997</td>\n",
       "      <td>-0.359465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.674860</td>\n",
       "      <td>0.610660</td>\n",
       "      <td>-0.387940</td>\n",
       "      <td>1.597522</td>\n",
       "      <td>0.263317</td>\n",
       "      <td>-0.631722</td>\n",
       "      <td>0.876372</td>\n",
       "      <td>0.641306</td>\n",
       "      <td>1.339280</td>\n",
       "      <td>0.289708</td>\n",
       "      <td>-0.400368</td>\n",
       "      <td>-0.323765</td>\n",
       "      <td>-0.299519</td>\n",
       "      <td>-0.359464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuantitySold  UnitPrice   Revenue     Month   Quarter      Year  \\\n",
       "0           2.0   1.356348  1.156912 -0.387940  0.642066  0.253843   \n",
       "1           6.0  -0.839786 -0.197489 -0.989865 -1.268845  0.253843   \n",
       "2          10.0   0.195256 -0.857951  0.815909  1.597522  0.253843   \n",
       "3          29.0   1.614186  1.486931  0.213984 -0.313389  0.263317   \n",
       "4          41.0   0.674860  0.610660 -0.387940  1.597522  0.263317   \n",
       "\n",
       "   CompetitorPricing  StockLevels  LeadTime  SupplierPerformance  \\\n",
       "0          -1.364285    -1.342198  1.500800             0.116193   \n",
       "1          -0.889651    -1.120341  1.623585             1.339280   \n",
       "2           0.385510     0.950325  0.027381             0.727737   \n",
       "3          -1.366513     1.578920  1.255230            -0.495350   \n",
       "4          -0.631722     0.876372  0.641306             1.339280   \n",
       "\n",
       "   ProductRatingsReviews  EconomicIndicators_Value  MarketTrends_Value  \\\n",
       "0              -0.681875                 -0.400524            1.771885   \n",
       "1               1.437943                 -0.400545           -0.372641   \n",
       "2               0.554685                 -0.375744           -0.372641   \n",
       "3              -1.653457                 -0.363912           -0.372639   \n",
       "4               0.289708                 -0.400368           -0.323765   \n",
       "\n",
       "   PurchaseHistory_Value  Features_Value  \n",
       "0              -0.123840       -0.356334  \n",
       "1              -0.300062       -0.359465  \n",
       "2              -0.300062        3.716853  \n",
       "3              -0.299997       -0.359465  \n",
       "4              -0.299519       -0.359464  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standardization to the numerical columns\n",
    "df_numerical[df_numerical.columns[1:]] = scaler.fit_transform(df_numerical[df_numerical.columns[1:]])\n",
    "df_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>WeatherConditions</th>\n",
       "      <th>PoliticalEvents</th>\n",
       "      <th>CustomerSegment</th>\n",
       "      <th>LaunchDate</th>\n",
       "      <th>LifeCycleStage</th>\n",
       "      <th>EconomicIndicators_Key</th>\n",
       "      <th>MarketTrends_Key</th>\n",
       "      <th>PurchaseHistory_Key</th>\n",
       "      <th>Features_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Population</td>\n",
       "      <td>Dryer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>Decline</td>\n",
       "      <td>election</td>\n",
       "      <td>toward</td>\n",
       "      <td>cause</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHb-183</td>\n",
       "      <td>Care</td>\n",
       "      <td>Washer</td>\n",
       "      <td>2022-08-23</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Youth</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>where</td>\n",
       "      <td>None</td>\n",
       "      <td>weight</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Job</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lead</td>\n",
       "      <td>onto</td>\n",
       "      <td>between</td>\n",
       "      <td>sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqe-765</td>\n",
       "      <td>Back</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>False</td>\n",
       "      <td>Adult</td>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>Growth</td>\n",
       "      <td>start</td>\n",
       "      <td>nation</td>\n",
       "      <td>team</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUN-031</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Washer</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>Maturity</td>\n",
       "      <td>direction</td>\n",
       "      <td>five</td>\n",
       "      <td>ever</td>\n",
       "      <td>turn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductID ProductName      Category   SalesDate      Channel   Weekday  \\\n",
       "0       NaN  Population         Dryer         NaN  Distributor   Tuesday   \n",
       "1   FHb-183        Care        Washer  2022-08-23  Distributor    Monday   \n",
       "2       NaN         Job     Microwave  2022-12-17     In-store  Saturday   \n",
       "3   Aqe-765        Back  Refrigerator  2023-04-15     In-store   Tuesday   \n",
       "4   NUN-031     Natural        Washer  2023-06-05       Online       NaN   \n",
       "\n",
       "  Holiday Promotions WeatherConditions PoliticalEvents CustomerSegment  \\\n",
       "0    True       True             Rainy             NaN          Senior   \n",
       "1   False       True            Cloudy             NaN           Youth   \n",
       "2   False       True            Cloudy           False             NaN   \n",
       "3   False        NaN            Cloudy           False           Adult   \n",
       "4    True      False             Rainy             NaN          Senior   \n",
       "\n",
       "   LaunchDate LifeCycleStage EconomicIndicators_Key MarketTrends_Key  \\\n",
       "0  2023-08-19        Decline               election           toward   \n",
       "1  2021-12-06   Introduction                  where             None   \n",
       "2  2023-11-09            NaN                   lead             onto   \n",
       "3  2021-09-27         Growth                  start           nation   \n",
       "4  2019-11-18       Maturity              direction             five   \n",
       "\n",
       "  PurchaseHistory_Key Features_Key  \n",
       "0               cause           my  \n",
       "1              weight         None  \n",
       "2             between         sure  \n",
       "3                team         None  \n",
       "4                ever         turn  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical = df.select_dtypes(exclude=[np.number])\n",
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the DataFrame columns to find those containing 'date'\n",
    "date_columns = [col for col in df_categorical.columns if 'date' in col.lower()]\n",
    "\n",
    "# Convert identified 'date' columns to datetime format\n",
    "for col in date_columns:\n",
    "    df_categorical[col] = pd.to_datetime(df_categorical[col])\n",
    "\n",
    "df_categorical = df_categorical.drop(columns=date_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   ProductID               90 non-null     object\n",
      " 1   ProductName             90 non-null     object\n",
      " 2   Category                90 non-null     object\n",
      " 3   Channel                 90 non-null     object\n",
      " 4   Weekday                 90 non-null     object\n",
      " 5   Holiday                 90 non-null     object\n",
      " 6   Promotions              90 non-null     object\n",
      " 7   WeatherConditions       90 non-null     object\n",
      " 8   PoliticalEvents         90 non-null     object\n",
      " 9   CustomerSegment         90 non-null     object\n",
      " 10  LifeCycleStage          90 non-null     object\n",
      " 11  EconomicIndicators_Key  90 non-null     object\n",
      " 12  MarketTrends_Key        90 non-null     object\n",
      " 13  PurchaseHistory_Key     90 non-null     object\n",
      " 14  Features_Key            90 non-null     object\n",
      "dtypes: object(15)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_categorical.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill nan values with deep learning prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductID                 10\n",
       "ProductName               10\n",
       "Category                  10\n",
       "Channel                   10\n",
       "Weekday                   10\n",
       "Holiday                   10\n",
       "Promotions                10\n",
       "WeatherConditions         10\n",
       "PoliticalEvents           10\n",
       "CustomerSegment           10\n",
       "LifeCycleStage            10\n",
       "EconomicIndicators_Key    10\n",
       "MarketTrends_Key          10\n",
       "PurchaseHistory_Key       10\n",
       "Features_Key              10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 73ms/step - loss: 2618.9177 - val_loss: 3293.3398\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2595.1184 - val_loss: 3274.7446\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2577.1338 - val_loss: 3255.4683\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2559.5933 - val_loss: 3234.2456\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2540.0977 - val_loss: 3209.7893\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2519.1926 - val_loss: 3181.4172\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2493.3208 - val_loss: 3147.6230\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2463.5615 - val_loss: 3107.1777\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2429.1064 - val_loss: 3058.0771\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2385.0627 - val_loss: 2999.5364\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2331.7234 - val_loss: 2930.3176\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2270.5105 - val_loss: 2848.7969\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2193.0076 - val_loss: 2753.3765\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2109.2109 - val_loss: 2642.1104\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2011.5859 - val_loss: 2515.6458\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1890.7023 - val_loss: 2372.7444\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1762.7843 - val_loss: 2211.5781\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1611.9655 - val_loss: 2036.7491\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1455.0015 - val_loss: 1849.4766\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1284.2137 - val_loss: 1656.9806\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1101.2081 - val_loss: 1463.4558\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 941.8624 - val_loss: 1280.2654\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 782.8614 - val_loss: 1120.2963\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 661.7308 - val_loss: 992.6227\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 572.8318 - val_loss: 905.2936\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 518.1913 - val_loss: 861.5536\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 509.0042 - val_loss: 857.6007\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 519.3362 - val_loss: 870.3309\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 530.4065 - val_loss: 887.9092\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 518.1570 - val_loss: 902.9398\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 492.2977 - val_loss: 914.5928\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 460.3320 - val_loss: 928.1624\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 440.2936 - val_loss: 939.8213\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 428.5392 - val_loss: 953.2446\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 419.1797 - val_loss: 964.0475\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 417.4613 - val_loss: 979.9060\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 412.1017 - val_loss: 985.1759\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 102ms/step - loss: 2641.4539 - val_loss: 2116.6267\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2607.5151 - val_loss: 2085.3838\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2572.8218 - val_loss: 2051.8860\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2532.7878 - val_loss: 2014.0913\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2486.0820 - val_loss: 1970.0399\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2432.9775 - val_loss: 1918.6230\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2370.5220 - val_loss: 1858.1783\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2298.3237 - val_loss: 1788.2502\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2209.6589 - val_loss: 1707.3950\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2110.8828 - val_loss: 1614.0249\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1990.5792 - val_loss: 1507.1001\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1858.3568 - val_loss: 1385.2388\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1705.6508 - val_loss: 1251.9409\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1541.4562 - val_loss: 1110.1360\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1368.6029 - val_loss: 962.6444\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1191.0015 - val_loss: 818.6354\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1017.4972 - val_loss: 688.9357\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 859.6489 - val_loss: 580.0040\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 740.4724 - val_loss: 501.8414\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 646.1477 - val_loss: 460.8181\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 607.9958 - val_loss: 447.1173\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 597.0090 - val_loss: 452.7322\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 598.1878 - val_loss: 460.5553\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 602.2419 - val_loss: 467.3356\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 595.8990 - val_loss: 466.2483\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 577.6176 - val_loss: 458.4721\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 559.4940 - val_loss: 448.9992\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 536.1469 - val_loss: 442.6163\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 522.3619 - val_loss: 439.0753\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 517.1465 - val_loss: 437.8615\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 510.6935 - val_loss: 435.3549\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 505.5340 - val_loss: 433.3334\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 498.5010 - val_loss: 431.6445\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 491.5322 - val_loss: 429.2347\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 484.6068 - val_loss: 430.7214\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 477.7404 - val_loss: 432.5335\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 472.6804 - val_loss: 435.8976\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 467.1102 - val_loss: 436.9167\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 464.1494 - val_loss: 438.1585\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 457.0757 - val_loss: 436.3829\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 450.4605 - val_loss: 438.2762\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 444.6298 - val_loss: 441.1683\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 439.4178 - val_loss: 446.6085\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 434.0768 - val_loss: 451.5741\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 61ms/step - loss: 9.2017 - val_loss: 8.6446\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.2336 - val_loss: 7.1467\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5.5701 - val_loss: 5.9445\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 4.4083 - val_loss: 5.1658\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.6072 - val_loss: 4.9053\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.4061 - val_loss: 4.9896\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.4122 - val_loss: 5.0991\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.4370 - val_loss: 5.0456\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.2633 - val_loss: 4.8451\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.0083 - val_loss: 4.7068\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.8206 - val_loss: 4.6259\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.6693 - val_loss: 4.5791\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.5792 - val_loss: 4.5659\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.5004 - val_loss: 4.5702\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.4295 - val_loss: 4.5754\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.3651 - val_loss: 4.5817\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2888 - val_loss: 4.5826\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.1964 - val_loss: 4.5860\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0903 - val_loss: 4.6003\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9923 - val_loss: 4.6293\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9206 - val_loss: 4.6673\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8469 - val_loss: 4.6959\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.7765 - val_loss: 4.6991\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 1.4600 - val_loss: 3.1267\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1382 - val_loss: 2.7693\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9751 - val_loss: 2.5928\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9197 - val_loss: 2.5364\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8648 - val_loss: 2.5485\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8181 - val_loss: 2.5918\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7579 - val_loss: 2.6738\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7038 - val_loss: 2.7674\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6505 - val_loss: 2.8514\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6088 - val_loss: 2.9475\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5728 - val_loss: 3.0271\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5298 - val_loss: 3.0531\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4921 - val_loss: 3.0744\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4544 - val_loss: 3.1140\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 55ms/step - loss: 19.7172 - val_loss: 19.2107\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 17.4440 - val_loss: 17.1595\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 15.3541 - val_loss: 15.1244\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 13.4384 - val_loss: 13.1345\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 11.5339 - val_loss: 11.1957\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.6744 - val_loss: 9.3551\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.8696 - val_loss: 7.6872\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.4383 - val_loss: 6.3116\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 5.2333 - val_loss: 5.3482\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 4.6318 - val_loss: 4.9282\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.3161 - val_loss: 4.9464\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.4598 - val_loss: 5.1348\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.3936 - val_loss: 5.1659\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4.1466 - val_loss: 5.0897\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.8308 - val_loss: 5.0354\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.5603 - val_loss: 5.0210\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.4012 - val_loss: 5.0587\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.3717 - val_loss: 5.0901\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.3065 - val_loss: 5.0802\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.1990 - val_loss: 5.0451\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 1.9811 - val_loss: 1.7261\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4484 - val_loss: 1.4300\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1094 - val_loss: 1.2857\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9226 - val_loss: 1.2527\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8789 - val_loss: 1.2809\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8503 - val_loss: 1.2847\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8085 - val_loss: 1.2762\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7533 - val_loss: 1.2514\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6893 - val_loss: 1.2257\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6337 - val_loss: 1.2057\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5903 - val_loss: 1.1888\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5535 - val_loss: 1.1793\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5167 - val_loss: 1.1739\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4852 - val_loss: 1.1725\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4506 - val_loss: 1.1688\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4164 - val_loss: 1.1691\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3832 - val_loss: 1.1846\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3554 - val_loss: 1.2024\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3294 - val_loss: 1.2125\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3028 - val_loss: 1.2174\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2742 - val_loss: 1.2233\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2519 - val_loss: 1.2317\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2266 - val_loss: 1.2333\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2064 - val_loss: 1.2401\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1838 - val_loss: 1.2523\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 62ms/step - loss: 1.5499 - val_loss: 1.1874\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2160 - val_loss: 1.0247\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0064 - val_loss: 0.9609\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8911 - val_loss: 0.9805\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8362 - val_loss: 1.0452\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7829 - val_loss: 1.0878\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7179 - val_loss: 1.0899\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6309 - val_loss: 1.0780\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5738 - val_loss: 1.0831\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5168 - val_loss: 1.1024\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4756 - val_loss: 1.1310\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4372 - val_loss: 1.1537\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4020 - val_loss: 1.1745\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 61ms/step - loss: 4.7517 - val_loss: 4.0286\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.6002 - val_loss: 3.2666\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.8202 - val_loss: 2.7861\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2345 - val_loss: 2.5911\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0429 - val_loss: 2.5836\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9448 - val_loss: 2.5952\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8704 - val_loss: 2.5775\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7175 - val_loss: 2.5222\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.5419 - val_loss: 2.4945\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4107 - val_loss: 2.4961\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.3171 - val_loss: 2.5123\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2322 - val_loss: 2.5340\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1601 - val_loss: 2.5570\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0958 - val_loss: 2.5879\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0317 - val_loss: 2.6338\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9615 - val_loss: 2.6729\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9079 - val_loss: 2.7137\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8526 - val_loss: 2.7366\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8109 - val_loss: 2.7443\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 54ms/step - loss: 1.7525 - val_loss: 1.3456\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2823 - val_loss: 1.1830\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0887 - val_loss: 1.1373\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9735 - val_loss: 1.1478\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9092 - val_loss: 1.1505\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8482 - val_loss: 1.1444\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7971 - val_loss: 1.1290\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7374 - val_loss: 1.0987\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6840 - val_loss: 1.0678\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6324 - val_loss: 1.0500\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5912 - val_loss: 1.0346\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5537 - val_loss: 1.0357\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5158 - val_loss: 1.0491\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4773 - val_loss: 1.0578\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4417 - val_loss: 1.0762\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4091 - val_loss: 1.0987\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3784 - val_loss: 1.1148\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3493 - val_loss: 1.1280\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3226 - val_loss: 1.1502\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2938 - val_loss: 1.1659\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2702 - val_loss: 1.1775\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 5.0327 - val_loss: 3.5194\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.9120 - val_loss: 2.6974\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.0874 - val_loss: 2.0995\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.4507 - val_loss: 1.6383\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.9946 - val_loss: 1.3270\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.6909 - val_loss: 1.1589\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.5063 - val_loss: 1.1357\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4937 - val_loss: 1.1924\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5490 - val_loss: 1.2247\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.5093 - val_loss: 1.1694\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.3831 - val_loss: 1.0783\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2539 - val_loss: 1.0165\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1648 - val_loss: 1.0060\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.1214 - val_loss: 1.0124\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0895 - val_loss: 1.0136\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0451 - val_loss: 1.0033\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9907 - val_loss: 0.9892\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9284 - val_loss: 0.9776\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8664 - val_loss: 0.9798\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8155 - val_loss: 0.9837\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7713 - val_loss: 0.9825\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7316 - val_loss: 0.9796\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6901 - val_loss: 0.9756\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6497 - val_loss: 0.9770\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6107 - val_loss: 0.9860\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5729 - val_loss: 0.9903\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5391 - val_loss: 0.9973\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5063 - val_loss: 1.0145\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4719 - val_loss: 1.0231\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4392 - val_loss: 1.0231\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4088 - val_loss: 1.0298\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3770 - val_loss: 1.0328\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3520 - val_loss: 1.0361\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 80ms/step - loss: 3.3450 - val_loss: 1.8124\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.5002 - val_loss: 1.3399\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.8419 - val_loss: 1.0805\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.4644 - val_loss: 1.0615\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2596 - val_loss: 1.2084\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2118 - val_loss: 1.3360\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1091 - val_loss: 1.2972\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9602 - val_loss: 1.2151\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8200 - val_loss: 1.1759\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7438 - val_loss: 1.1566\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6726 - val_loss: 1.1779\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6137 - val_loss: 1.2140\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5627 - val_loss: 1.2702\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5213 - val_loss: 1.3017\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 2520.6855 - val_loss: 2244.6963\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2499.3772 - val_loss: 2226.3923\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2476.8384 - val_loss: 2205.6521\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2450.5803 - val_loss: 2180.8906\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2420.5732 - val_loss: 2150.3748\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2383.4990 - val_loss: 2113.4126\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2340.2751 - val_loss: 2068.6685\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2286.3357 - val_loss: 2016.1842\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2224.2114 - val_loss: 1954.8384\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2146.1697 - val_loss: 1882.3025\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2060.0127 - val_loss: 1797.7427\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1953.7318 - val_loss: 1700.7468\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1833.8306 - val_loss: 1590.0142\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1697.7864 - val_loss: 1465.9905\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1548.0122 - val_loss: 1331.3911\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1385.8116 - val_loss: 1188.5972\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1222.9639 - val_loss: 1044.0983\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1043.8706 - val_loss: 907.1797\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 894.7211 - val_loss: 784.7651\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 744.5339 - val_loss: 686.7816\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 638.4408 - val_loss: 611.9498\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 570.6810 - val_loss: 567.0563\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 528.9637 - val_loss: 548.9582\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 507.6268 - val_loss: 546.3794\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 504.5919 - val_loss: 552.2072\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 503.4616 - val_loss: 558.9727\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 496.9652 - val_loss: 560.9322\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 478.5545 - val_loss: 555.2546\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 454.2946 - val_loss: 549.1519\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 437.6394 - val_loss: 544.9859\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 420.2641 - val_loss: 545.3657\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 410.7322 - val_loss: 544.6899\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 405.5374 - val_loss: 546.0670\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 398.0561 - val_loss: 550.1536\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 390.7570 - val_loss: 554.2698\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 383.5060 - val_loss: 556.6866\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 376.7458 - val_loss: 558.3221\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 370.1865 - val_loss: 557.7374\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 364.8908 - val_loss: 558.6262\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 359.1183 - val_loss: 559.8700\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 353.9183 - val_loss: 562.0333\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 348.3707 - val_loss: 561.3920\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 2398.1416 - val_loss: 2285.3728\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2369.6433 - val_loss: 2262.4089\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2344.6318 - val_loss: 2238.9426\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2317.0693 - val_loss: 2213.3755\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2288.1904 - val_loss: 2184.8142\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2254.1619 - val_loss: 2151.9561\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2216.1755 - val_loss: 2113.6077\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2168.9561 - val_loss: 2070.0168\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2113.7773 - val_loss: 2019.0181\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2050.7092 - val_loss: 1960.3945\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1980.5377 - val_loss: 1893.1624\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1893.6337 - val_loss: 1818.1143\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1792.6956 - val_loss: 1733.6938\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1686.8405 - val_loss: 1639.4510\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1564.2710 - val_loss: 1538.8848\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1424.5858 - val_loss: 1433.6810\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1289.0189 - val_loss: 1326.1050\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1138.2678 - val_loss: 1221.4672\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 976.4360 - val_loss: 1124.0852\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 833.2443 - val_loss: 1038.1378\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 702.1136 - val_loss: 970.8958\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 581.1482 - val_loss: 928.7709\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 513.1069 - val_loss: 914.3472\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 467.9019 - val_loss: 925.9177\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 441.4309 - val_loss: 948.1943\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 443.6242 - val_loss: 968.5735\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 439.0468 - val_loss: 977.4542\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 433.2644 - val_loss: 974.0858\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 421.2265 - val_loss: 955.1511\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 405.8571 - val_loss: 928.9339\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 384.1880 - val_loss: 907.5931\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 370.1689 - val_loss: 890.5530\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 360.3858 - val_loss: 881.3433\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 353.0265 - val_loss: 874.5916\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 349.8151 - val_loss: 870.9130\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 347.1042 - val_loss: 870.5389\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 340.9623 - val_loss: 872.3035\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 333.8255 - val_loss: 871.5220\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 326.1998 - val_loss: 870.4254\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 319.1718 - val_loss: 872.5397\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 312.1728 - val_loss: 876.2149\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 306.3308 - val_loss: 879.0471\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 301.8580 - val_loss: 880.9797\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 296.5738 - val_loss: 882.8050\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 291.8675 - val_loss: 883.2533\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 287.7426 - val_loss: 882.9682\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 284.2121 - val_loss: 880.7234\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 280.9115 - val_loss: 880.9700\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 275.8045 - val_loss: 881.8435\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 52ms/step - loss: 2650.2397 - val_loss: 1638.7532\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2621.2676 - val_loss: 1615.7039\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2590.7783 - val_loss: 1590.3452\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2558.0554 - val_loss: 1561.3983\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2521.5078 - val_loss: 1529.2257\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2478.4988 - val_loss: 1492.8563\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2431.1763 - val_loss: 1451.5763\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2371.9509 - val_loss: 1404.8915\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2307.3518 - val_loss: 1351.2946\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2232.8928 - val_loss: 1290.0559\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2145.1851 - val_loss: 1221.8514\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2045.9017 - val_loss: 1145.8573\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1939.7107 - val_loss: 1062.2012\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1811.0497 - val_loss: 972.5413\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1677.7913 - val_loss: 876.8096\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1535.6057 - val_loss: 778.4834\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1383.4652 - val_loss: 681.5665\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1223.8271 - val_loss: 587.5012\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1063.1217 - val_loss: 501.3622\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 912.8958 - val_loss: 430.0609\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 779.4675 - val_loss: 379.9116\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 657.3688 - val_loss: 356.6064\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 577.2398 - val_loss: 361.1818\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 535.6775 - val_loss: 388.8961\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 508.3683 - val_loss: 424.3357\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 506.5002 - val_loss: 457.2946\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 504.7228 - val_loss: 484.8369\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 494.1830 - val_loss: 501.6526\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 477.2891 - val_loss: 502.5582\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 459.8109 - val_loss: 498.1456\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 440.5984 - val_loss: 496.2369\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 429.6038 - val_loss: 498.5155\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 54ms/step - loss: 2500.8542 - val_loss: 3014.9329\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2468.7603 - val_loss: 2979.8662\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2436.2542 - val_loss: 2940.1865\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2398.1931 - val_loss: 2897.4617\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2358.3442 - val_loss: 2850.3062\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2312.4575 - val_loss: 2796.6572\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2263.1301 - val_loss: 2733.8965\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2200.3516 - val_loss: 2661.3933\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2130.1746 - val_loss: 2577.6045\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2046.0405 - val_loss: 2481.6902\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1954.2368 - val_loss: 2372.9370\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1850.5458 - val_loss: 2252.2390\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1729.7399 - val_loss: 2119.6082\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1602.3538 - val_loss: 1973.2817\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1459.7716 - val_loss: 1819.4264\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1305.8370 - val_loss: 1661.0608\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1155.9928 - val_loss: 1497.3641\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 993.1478 - val_loss: 1336.1560\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 851.2228 - val_loss: 1183.9690\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 711.9786 - val_loss: 1057.0692\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 600.2524 - val_loss: 962.9831\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 527.6583 - val_loss: 904.8737\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 475.9498 - val_loss: 879.7327\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 451.0746 - val_loss: 876.5464\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 444.3226 - val_loss: 885.8702\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 436.8242 - val_loss: 891.7908\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 424.1307 - val_loss: 895.4265\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 410.9691 - val_loss: 896.2379\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 395.6855 - val_loss: 895.4353\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 385.5681 - val_loss: 894.7439\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 374.7606 - val_loss: 896.5032\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 367.7842 - val_loss: 900.4571\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 361.3863 - val_loss: 904.0139\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 354.7080 - val_loss: 910.4839\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def fill_missing_with_dl_categorical(df, column):\n",
    "    # Copy the DataFrame to avoid changes to the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Initialize LabelEncoder for all columns\n",
    "    le_dict = {}\n",
    "    for col in df_copy.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Convert NaN to a placeholder string and then encode\n",
    "        df_copy[col] = le.fit_transform(df_copy[col].fillna('Missing').astype(str))\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    # Define features and target\n",
    "    features = [col for col in df_copy.columns if col != column]\n",
    "    X = df_copy[features]\n",
    "    y = df_copy[column]\n",
    "    \n",
    "    # Handle missing values in features\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "    # Normalize the input features\n",
    "    X_mean = np.mean(X_imputed, axis=0)\n",
    "    X_std = np.std(X_imputed, axis=0)\n",
    "    X_normalized = (X_imputed - X_mean) / (X_std + 1e-6)\n",
    "\n",
    "    # Identify rows with missing target values after encoding ('Missing' placeholder)\n",
    "    if 'Missing' in le_dict[column].classes_:\n",
    "        missing_value_encoded = le_dict[column].transform(['Missing'])[0]\n",
    "        missing_indices = (y == missing_value_encoded)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X_normalized[~missing_indices]\n",
    "    y_train = y[~missing_indices]\n",
    "    X_predict = X_normalized[missing_indices]\n",
    "\n",
    "    # Check if there's anything to predict\n",
    "    if not X_predict.size:\n",
    "        return df\n",
    "    \n",
    "    # Define the deep learning model\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression-like approach\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Train the model\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train_split, y_train_split, validation_data=(X_val_split, y_val_split), epochs=200, callbacks=[early_stopping], batch_size=32)\n",
    "    \n",
    "    # Predict the missing values\n",
    "    predicted_values = model.predict(X_predict).flatten()\n",
    "    \n",
    "    # Inverse transform the predicted values back to original categories, ignoring 'Missing'\n",
    "    predicted_categories = le_dict[column].inverse_transform(np.round(predicted_values).astype(int))\n",
    "    df.loc[df[column].isna(), column] = predicted_categories\n",
    "\n",
    "    return df\n",
    "\n",
    "for column in df_categorical.columns.to_list():\n",
    "    df_categorical = fill_missing_with_dl_categorical(df_categorical, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductID                 0\n",
       "ProductName               0\n",
       "Category                  0\n",
       "Channel                   0\n",
       "Weekday                   0\n",
       "Holiday                   0\n",
       "Promotions                0\n",
       "WeatherConditions         0\n",
       "PoliticalEvents           0\n",
       "CustomerSegment           0\n",
       "LifeCycleStage            0\n",
       "EconomicIndicators_Key    0\n",
       "MarketTrends_Key          0\n",
       "PurchaseHistory_Key       0\n",
       "Features_Key              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Category</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Promotions</th>\n",
       "      <th>WeatherConditions</th>\n",
       "      <th>PoliticalEvents</th>\n",
       "      <th>CustomerSegment</th>\n",
       "      <th>LifeCycleStage</th>\n",
       "      <th>EconomicIndicators_Key</th>\n",
       "      <th>MarketTrends_Key</th>\n",
       "      <th>PurchaseHistory_Key</th>\n",
       "      <th>Features_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WVP-224</td>\n",
       "      <td>Population</td>\n",
       "      <td>Dryer</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>False</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Decline</td>\n",
       "      <td>election</td>\n",
       "      <td>toward</td>\n",
       "      <td>cause</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FHb-183</td>\n",
       "      <td>Care</td>\n",
       "      <td>Washer</td>\n",
       "      <td>Distributor</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>True</td>\n",
       "      <td>Youth</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>where</td>\n",
       "      <td>of</td>\n",
       "      <td>weight</td>\n",
       "      <td>medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frB-431</td>\n",
       "      <td>Job</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>False</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Growth</td>\n",
       "      <td>lead</td>\n",
       "      <td>onto</td>\n",
       "      <td>between</td>\n",
       "      <td>sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aqe-765</td>\n",
       "      <td>Back</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>False</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Growth</td>\n",
       "      <td>start</td>\n",
       "      <td>nation</td>\n",
       "      <td>team</td>\n",
       "      <td>once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NUN-031</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Washer</td>\n",
       "      <td>Online</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Maturity</td>\n",
       "      <td>direction</td>\n",
       "      <td>five</td>\n",
       "      <td>ever</td>\n",
       "      <td>turn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductID ProductName      Category      Channel   Weekday Holiday  \\\n",
       "0   WVP-224  Population         Dryer  Distributor   Tuesday    True   \n",
       "1   FHb-183        Care        Washer  Distributor    Monday   False   \n",
       "2   frB-431         Job     Microwave     In-store  Saturday   False   \n",
       "3   Aqe-765        Back  Refrigerator     In-store   Tuesday   False   \n",
       "4   NUN-031     Natural        Washer       Online  Saturday    True   \n",
       "\n",
       "  Promotions WeatherConditions PoliticalEvents CustomerSegment LifeCycleStage  \\\n",
       "0       True             Rainy           False          Senior        Decline   \n",
       "1       True            Cloudy            True           Youth   Introduction   \n",
       "2       True            Cloudy           False         Missing         Growth   \n",
       "3    Missing            Cloudy           False           Adult         Growth   \n",
       "4      False             Rainy         Missing          Senior       Maturity   \n",
       "\n",
       "  EconomicIndicators_Key MarketTrends_Key PurchaseHistory_Key Features_Key  \n",
       "0               election           toward               cause           my  \n",
       "1                  where               of              weight      medical  \n",
       "2                   lead             onto             between         sure  \n",
       "3                  start           nation                team         once  \n",
       "4              direction             five                ever         turn  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply unique values as 'other' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_categorical.columns:\n",
    "    value_counts = df_categorical[column].value_counts()\n",
    "    unique_values = value_counts[value_counts == 1].index.tolist()\n",
    "    df_categorical[column] = df_categorical[column].apply(lambda x: 'other' if x in unique_values else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductID\n",
      "other      80\n",
      "WVP-224     2\n",
      "frB-431     2\n",
      "XWL-477     2\n",
      "eXu-255     2\n",
      "WYQ-059     2\n",
      "XfO-687     2\n",
      "bmP-687     2\n",
      "fHD-956     2\n",
      "axh-757     2\n",
      "dFy-336     2\n",
      "Name: count, dtype: int64\n",
      "ProductName\n",
      "other       75\n",
      "Indicate     3\n",
      "Job          2\n",
      "Our          2\n",
      "General      2\n",
      "Impact       2\n",
      "Instead      2\n",
      "What         2\n",
      "None         2\n",
      "Keep         2\n",
      "Know         2\n",
      "Game         2\n",
      "Window       2\n",
      "Name: count, dtype: int64\n",
      "Category\n",
      "Washer          24\n",
      "Oven            23\n",
      "Dryer           22\n",
      "Refrigerator    17\n",
      "Microwave       11\n",
      "Missing          3\n",
      "Name: count, dtype: int64\n",
      "Channel\n",
      "Distributor    40\n",
      "In-store       40\n",
      "Online         19\n",
      "other           1\n",
      "Name: count, dtype: int64\n",
      "Weekday\n",
      "Sunday       20\n",
      "Saturday     16\n",
      "Thursday     16\n",
      "Tuesday      14\n",
      "Wednesday    12\n",
      "Monday       11\n",
      "Friday       11\n",
      "Name: count, dtype: int64\n",
      "Holiday\n",
      "True       47\n",
      "False      43\n",
      "Missing     9\n",
      "other       1\n",
      "Name: count, dtype: int64\n",
      "Promotions\n",
      "True       47\n",
      "False      43\n",
      "Missing    10\n",
      "Name: count, dtype: int64\n",
      "WeatherConditions\n",
      "Rainy     28\n",
      "Snowy     27\n",
      "Cloudy    26\n",
      "Sunny     18\n",
      "other      1\n",
      "Name: count, dtype: int64\n",
      "PoliticalEvents\n",
      "False      49\n",
      "True       41\n",
      "Missing     6\n",
      "False       3\n",
      "other       1\n",
      "Name: count, dtype: int64\n",
      "CustomerSegment\n",
      "Senior     33\n",
      "Youth      32\n",
      "Adult      30\n",
      "Missing     5\n",
      "Name: count, dtype: int64\n",
      "LifeCycleStage\n",
      "Maturity        26\n",
      "Introduction    25\n",
      "Growth          25\n",
      "Decline         24\n",
      "Name: count, dtype: int64\n",
      "EconomicIndicators_Key\n",
      "other        71\n",
      "idea          3\n",
      "push          2\n",
      "phone         2\n",
      "impact        2\n",
      "middle        2\n",
      "maintain      2\n",
      "drug          2\n",
      "sure          2\n",
      "raise         2\n",
      "here          2\n",
      "ground        2\n",
      "religious     2\n",
      "so            2\n",
      "join          2\n",
      "Name: count, dtype: int64\n",
      "MarketTrends_Key\n",
      "other          71\n",
      "government      3\n",
      "of              2\n",
      "onto            2\n",
      "offer           2\n",
      "adult           2\n",
      "large           2\n",
      "better          2\n",
      "matter          2\n",
      "himself         2\n",
      "mean            2\n",
      "education       2\n",
      "institution     2\n",
      "own             2\n",
      "financial       2\n",
      "Name: count, dtype: int64\n",
      "PurchaseHistory_Key\n",
      "other         67\n",
      "full           3\n",
      "fund           2\n",
      "song           2\n",
      "where          2\n",
      "door           2\n",
      "knowledge      2\n",
      "position       2\n",
      "image          2\n",
      "weight         2\n",
      "eye            2\n",
      "move           2\n",
      "generation     2\n",
      "let            2\n",
      "ever           2\n",
      "team           2\n",
      "former         2\n",
      "Name: count, dtype: int64\n",
      "Features_Key\n",
      "other      77\n",
      "medical     3\n",
      "once        3\n",
      "of          3\n",
      "product     2\n",
      "keep        2\n",
      "pick        2\n",
      "meet        2\n",
      "model       2\n",
      "happy       2\n",
      "work        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df_categorical.columns:\n",
    "    print(df_categorical[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply one hot encoding for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_Microwave</th>\n",
       "      <th>Category_Missing</th>\n",
       "      <th>Category_Oven</th>\n",
       "      <th>Category_Refrigerator</th>\n",
       "      <th>Category_Washer</th>\n",
       "      <th>Channel_In-store</th>\n",
       "      <th>Channel_Online</th>\n",
       "      <th>Channel_other</th>\n",
       "      <th>Weekday_Monday</th>\n",
       "      <th>Weekday_Saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>PoliticalEvents_True</th>\n",
       "      <th>PoliticalEvents_False</th>\n",
       "      <th>PoliticalEvents_Missing</th>\n",
       "      <th>PoliticalEvents_other</th>\n",
       "      <th>CustomerSegment_Missing</th>\n",
       "      <th>CustomerSegment_Senior</th>\n",
       "      <th>CustomerSegment_Youth</th>\n",
       "      <th>LifeCycleStage_Growth</th>\n",
       "      <th>LifeCycleStage_Introduction</th>\n",
       "      <th>LifeCycleStage_Maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_Microwave  Category_Missing  Category_Oven  Category_Refrigerator  \\\n",
       "0                   0                 0              0                      0   \n",
       "1                   0                 0              0                      0   \n",
       "2                   1                 0              0                      0   \n",
       "3                   0                 0              0                      1   \n",
       "4                   0                 0              0                      0   \n",
       "\n",
       "   Category_Washer  Channel_In-store  Channel_Online  Channel_other  \\\n",
       "0                0                 0               0              0   \n",
       "1                1                 0               0              0   \n",
       "2                0                 1               0              0   \n",
       "3                0                 1               0              0   \n",
       "4                1                 0               1              0   \n",
       "\n",
       "   Weekday_Monday  Weekday_Saturday  ...  PoliticalEvents_True  \\\n",
       "0               0                 0  ...                     0   \n",
       "1               1                 0  ...                     0   \n",
       "2               0                 1  ...                     0   \n",
       "3               0                 0  ...                     0   \n",
       "4               0                 1  ...                     0   \n",
       "\n",
       "   PoliticalEvents_False  PoliticalEvents_Missing  PoliticalEvents_other  \\\n",
       "0                      1                        0                      0   \n",
       "1                      0                        0                      1   \n",
       "2                      0                        0                      0   \n",
       "3                      0                        0                      0   \n",
       "4                      0                        1                      0   \n",
       "\n",
       "   CustomerSegment_Missing  CustomerSegment_Senior  CustomerSegment_Youth  \\\n",
       "0                        0                       1                      0   \n",
       "1                        0                       0                      1   \n",
       "2                        1                       0                      0   \n",
       "3                        0                       0                      0   \n",
       "4                        0                       1                      0   \n",
       "\n",
       "   LifeCycleStage_Growth  LifeCycleStage_Introduction  LifeCycleStage_Maturity  \n",
       "0                      0                            0                        0  \n",
       "1                      0                            1                        0  \n",
       "2                      1                            0                        0  \n",
       "3                      1                            0                        0  \n",
       "4                      0                            0                        1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical_encoded = pd.get_dummies(df_categorical.iloc[:, 2:-4], drop_first=True).astype('int')\n",
    "del df_categorical\n",
    "df_categorical_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuantitySold</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>CompetitorPricing</th>\n",
       "      <th>StockLevels</th>\n",
       "      <th>LeadTime</th>\n",
       "      <th>SupplierPerformance</th>\n",
       "      <th>...</th>\n",
       "      <th>PoliticalEvents_True</th>\n",
       "      <th>PoliticalEvents_False</th>\n",
       "      <th>PoliticalEvents_Missing</th>\n",
       "      <th>PoliticalEvents_other</th>\n",
       "      <th>CustomerSegment_Missing</th>\n",
       "      <th>CustomerSegment_Senior</th>\n",
       "      <th>CustomerSegment_Youth</th>\n",
       "      <th>LifeCycleStage_Growth</th>\n",
       "      <th>LifeCycleStage_Introduction</th>\n",
       "      <th>LifeCycleStage_Maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.356348</td>\n",
       "      <td>1.156912</td>\n",
       "      <td>-0.387940</td>\n",
       "      <td>0.642066</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>-1.364285</td>\n",
       "      <td>-1.342198</td>\n",
       "      <td>1.500800</td>\n",
       "      <td>0.116193</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.839786</td>\n",
       "      <td>-0.197489</td>\n",
       "      <td>-0.989865</td>\n",
       "      <td>-1.268845</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>-0.889651</td>\n",
       "      <td>-1.120341</td>\n",
       "      <td>1.623585</td>\n",
       "      <td>1.339280</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.195256</td>\n",
       "      <td>-0.857951</td>\n",
       "      <td>0.815909</td>\n",
       "      <td>1.597522</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>0.385510</td>\n",
       "      <td>0.950325</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.727737</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.614186</td>\n",
       "      <td>1.486931</td>\n",
       "      <td>0.213984</td>\n",
       "      <td>-0.313389</td>\n",
       "      <td>0.263317</td>\n",
       "      <td>-1.366513</td>\n",
       "      <td>1.578920</td>\n",
       "      <td>1.255230</td>\n",
       "      <td>-0.495350</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.674860</td>\n",
       "      <td>0.610660</td>\n",
       "      <td>-0.387940</td>\n",
       "      <td>1.597522</td>\n",
       "      <td>0.263317</td>\n",
       "      <td>-0.631722</td>\n",
       "      <td>0.876372</td>\n",
       "      <td>0.641306</td>\n",
       "      <td>1.339280</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuantitySold  UnitPrice   Revenue     Month   Quarter      Year  \\\n",
       "0           2.0   1.356348  1.156912 -0.387940  0.642066  0.253843   \n",
       "1           6.0  -0.839786 -0.197489 -0.989865 -1.268845  0.253843   \n",
       "2          10.0   0.195256 -0.857951  0.815909  1.597522  0.253843   \n",
       "3          29.0   1.614186  1.486931  0.213984 -0.313389  0.263317   \n",
       "4          41.0   0.674860  0.610660 -0.387940  1.597522  0.263317   \n",
       "\n",
       "   CompetitorPricing  StockLevels  LeadTime  SupplierPerformance  ...  \\\n",
       "0          -1.364285    -1.342198  1.500800             0.116193  ...   \n",
       "1          -0.889651    -1.120341  1.623585             1.339280  ...   \n",
       "2           0.385510     0.950325  0.027381             0.727737  ...   \n",
       "3          -1.366513     1.578920  1.255230            -0.495350  ...   \n",
       "4          -0.631722     0.876372  0.641306             1.339280  ...   \n",
       "\n",
       "   PoliticalEvents_True  PoliticalEvents_False  PoliticalEvents_Missing  \\\n",
       "0                     0                      1                        0   \n",
       "1                     0                      0                        0   \n",
       "2                     0                      0                        0   \n",
       "3                     0                      0                        0   \n",
       "4                     0                      0                        1   \n",
       "\n",
       "   PoliticalEvents_other  CustomerSegment_Missing  CustomerSegment_Senior  \\\n",
       "0                      0                        0                       1   \n",
       "1                      1                        0                       0   \n",
       "2                      0                        1                       0   \n",
       "3                      0                        0                       0   \n",
       "4                      0                        0                       1   \n",
       "\n",
       "   CustomerSegment_Youth  LifeCycleStage_Growth  LifeCycleStage_Introduction  \\\n",
       "0                      0                      0                            0   \n",
       "1                      1                      0                            1   \n",
       "2                      0                      1                            0   \n",
       "3                      0                      1                            0   \n",
       "4                      0                      0                            0   \n",
       "\n",
       "   LifeCycleStage_Maturity  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have two datasets named df1 and df2\n",
    "concatenated_df = pd.concat([df_numerical, df_categorical_encoded], axis=1)\n",
    "del df_numerical, df_categorical_encoded\n",
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
